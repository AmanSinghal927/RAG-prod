["Learner Name: Date Started: Date Completed: Successful Completion: Yes___ No___ Goal Path: Employment Apprenticeship Secondary School___ Post Secondary Independence___ Task Description: Complete an agenda for a training schedule and traveling times. Competency: A: Find and Use Information B: Communicate Ideas and Information C: Understand and Use Numbers D: Use Digital Technology Task Group(s): A1: Read continuous text A2: Interpret documents B3: Complete and create documents C2: Manage time C4: Manage Data D2: Use Digital Technology Level Indicators: A1.1: Read brief texts to locate specific details A2.2: Interpret simple documents to locate and connect information B3.2a: Use layout to determine where to make entries in simple documents B3.2b: Create simple documents to sort, display and organize information C2.1: Measure time and make simple calculations C4.1: Make simple comparisons and calculations D.2: Perform well-defined, multi-step digital tasks Performance Descriptors: see chart on last page Materials Required: Pen and Paper Computer with a word processing program or spreadsheet program", "Task 1: Complete the weekly agenda using the class schedule. Include the class code. Task 2: Using the Express and Regular bus schedules, locate the times that you will be catching the bus at the Downtown Terminal to arrive at the college on time for all classes. Enter the information into the agenda for each day. You should arrive at class 15 minutes before it begins. Task 3: You are meeting friends downtown for dinner at 6 p.m. on Wednesday. What time does the bus leave after your last class on Wednesday that would allow you to meet your friends on time Task 4: Name the two buildings where your classes will be held according to the class schedule.", "Monday Tuesday Wednesday Thursday Friday 7 7 7 7 7 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 Evening Evening Evening Evening Evening", "Depart Downtown Arrive at College Depart College Arrive Downtown 6:30 am 6:55 am 7:00 am 7:25 am 7:30 am 7:55 am 8:00 am 8:25 am 8:30 am 8:55 am 9:00 am 9:25 am 9:30 am 9:55 am 10:00 am 10:25 am 10:30 am 10:55 am 11:00 am 11:25 am 1:30 pm 1:55 pm 2:00 pm 2:25 pm 2:30 pm 2:55 pm 3:00 pm 3:25 pm 3:30 pm 3:55 pm 4:00 pm 4:25 pm 4:30 pm 4:55 pm 5:00 pm 5:25 pm", "Depart Downtown Arrive/Depart College Arrive Downtown 6:00 am 6:40 am 7:20 am 6:40 am 7:20 am 8:00 am 7: 20 am 8:00 am 8:40 am 8:00 am 8:40 am 9:20 am 8:40 am 9:20 am 10:00 am 9:20 am 10:00 am 10:40 am 10:00 am 10:40 am 11:20 am 10:40 am 11:20 am 12:00 pm 11:20 am 12:00 pm 12:40 pm 12:00 pm 12:40 pm 1:20 pm 12:40 1:20 pm 2:00 pm 1:20 pm 2:00 pm 2:40 pm 2:00 pm 2:40 pm 3:20 pm 2:40 pm 3:20 pm 4:00 pm 3:20 pm 4:00 pm 4:40 pm 4:00 pm 4:40 pm 5:20 pm 4:40 pm 5:20 pm 6:00 pm 5:20 pm 6:00 pm 6:40 pm 6:00 pm 6:40 pm 7:20 pm 6:40 pm 7:20 pm 8:00 pm 7:20 pm 8:00 pm 8:40 pm 8:00 pm 8:40 pm 9:20 pm 8:40 pm 9:20 pm 10:00 pm 9:20 pm 10:00 pm 10:40 pm 10:00 pm 10:40 pm 11:20 pm 10:40 pm 11:20 pm 12:00 am", "Monday Tuesday Wednesday Thursday Friday 7 7 7 7 7 8 Laws 30-CO1 8 Laws 79-CO1 8 8 8 Laws 32-CO1 9 9 9 9 9 10 10 Laws 79-SO1 10 10 FLPL 45-CO1 10 Recr 9-LO1 11 Laws 32-SO1 11 11 11 11 12 12 Soci 50-SO1 12 Laws 18-CO1 12 Laws 83-CO1 12 1 1 1 1 1 2 2 2 RecR 9-L01 2 Laws 18-SO1 2 3 3 3 3 3 4 4 4 Laws 83-SO1 4 4 5 5 5 5 5 6 6 6 6 6 Evening Evening Evening Evening Evening", "Monday Tuesday Wednesday Thursday Friday 7 Regular bus - 6:40 Express bus   6:30 7 Regular bus - 6:40 Express bus   6:30 7 Regular bus   10:40 Express bus   10:30 7 Regular bus   8:40 Express bus   8:30 7 Regular bus - 6:40 Express bus   6:30 8 Laws 30-CO1 8 Laws 79-CO1 8 8 8 Laws 32-CO1 9 9 9 9 9 10 10 Laws 79-SO1 10 10 FLPL 45-CO1 10 Recr 9-LO1 11 Laws 32-SO1 11 11 11 11 12 12 Soci 50-SO1 12 Laws 18-CO1 12 Laws 83-CO1 12 1 1 1 1 1 2 2 2 RecR 9-L01 2 Laws 18-SO1 2 3 3 3 3 3 4 4 4 Laws 83-SO1 4 4 5 5 5 5 5 6 6 6 6 6 Task Task 3: You The Brealey bus are 4: leave Name Evening the and the meeting friends downtown college after your two locations where Evening leaves at 5:20 pm PTBO Sport and lastyour for dinner at 6 classes will be Wellness Centre Evening class on Wednesday p.m. held Evening on Wednesday. according to the What class time does the bus schedule. Evening", "Performance Descriptors Needs Work Completes task with support from practitioner Completes task independently A1.1 reads short texts to locate a single piece of information follows the sequence of events in straightforward chronological texts follow simple, straightforward instructional texts identifies the main idea in brief texts A2.2 performs limited searches using one or two search criteria extracts information from tables and forms uses layout to locate information makes connections between parts of documents makes low-level inferences B3.2a uses layout to determine where to make entries begins to make some inferences to decide what information is needed, where and how to enter the information makes entries using a limited range of vocabulary follows instructions on documents B3.2b follows conventions to display information in simple documents (e.g. use of font, colour, shading, bulleted lists) sorts entries into categories displays one or two categories of information organized according to content to be presented identifies parts of documents using titles, row and column headings and labels C2.1 recognizes values in number and word format understands chronological order understands and uses common date formats reads time on analog and digital clocks identifies and performs required operation represents dates and times using standard conventions measures time using common instruments, such as clocks, timers and stopwatches chooses appropriate units of measurement (e.g. hours, minutes, seconds) interprets and represents time using whole numbers, decimals (e.g. .25, .5) and simple common fractions (e.g.  ,   hour) follows apparent steps to reach solutions uses strategies to check accuracy (e.g. estimating, using a calculator, repeating a calculation, using the reverse operation) C4.1 recognizes values in number and word format understands numerical order identifies and performs required operation makes simple estimates follows apparent steps to reach solutions recognizes simple patterns uses strategies to check accuracy (e.g. estimating, using a calculator, repeating a calculation, using the reverse operation) D.2 selects and follows appropriate steps to complete tasks locates and recognizes functions and commands makes low-level inferences to interpret icons and text begins to identify sources and evaluate information performs simple searches using keywords (e.g. internet, software help menu)", "Membership Grade Number of People Section Annual Dues Fellow 24 $25 Member 153 $25 Institute Affiliate 8 $25 Student Member 47 $0* Esteemed Colleague 6 $0 TOTAL 238", "Date Meeting Subject Location Attendees 4-10-07 April - Joint meeting with WTS Kris Strickler and Danielle Cogan gave a presentation on the Columbia River Crossing project on the I-5 bridge that connects Oregon and Washington. Embassy Suites Hotel Portland, OR 60 5-18-07 May - Joint meeting with Oregon Traffic Control Devices Committee (OTCDC) Sections newly elected officers were announced and a presentation on the Highway 25 emergency reconstruction efforts that followed a large storm on Mt. Hood early 2007. Crowne Plaza Hotel, Lake Oswego, OR 45 7-15 to 7-18-07 Joint 2007 ITE Western District (District 6) Annual Meeting & Quad Conference Oregon ITE section hosted a very successful joint 2007 ITE District 6 Annual Meeting & Quad Conference in Portland. This year s annual meeting broke many previous records with over 500 meeting participants at the meeting. Hilton Hotel, Portland, OR 500 9-21-07 2007 Golf Tournament Due to timing of ITE District 6 conference in Portland, this year s golf tournament was held in late summer. We had good turn out and good corporate sponsorship donations. Oregon Golf Association (OGA) Golf Course, Woodburn, OR 57 9-25-07 September Meeting Jim Peters (DKS Associates) and Jay McCoy (City of Gresham) gave a presentation on the use of recent SCATS Adaptive Traffic Signal System in City of Gresham, Oregon. Kells Irish Pub Portland, OR 56 10-23-07 October Meeting Senator Rick Metsger, Chairman of the Senate Transportation Committee, discussed about congestion pricing and his  Moving Oregon  statewide transportation tour, and effort to build support for major investment in Oregon s transportation system. Hotel Monaco, Portland, OR 73 11-15-07 2007 Student Traffic Bowl Oregon ITE 16th Annual Student Traffic Bowl competition featured six universities from around the northwest. This year s 1st place prize went to University of Portland, while University of Washington and Oregon Institute of Technologies (OIT) both tied for 2nd place. McMenamins Edgefield Troutdale, OR 123 Including 52 students 1-29-08 January Technical Workshop The Section sponsored a workshop on tort, liability, ethics, and professionalism in transportation with featured speakers John Mason (Penn State University), Rayann Speakman (FHWA), Karen Dixon (Oregon State University), Mike Coleman (City of Portland), Brian Ray, Beth Wemple (Kittelson and Associates), and Ken Crowley (Oregon DOJ). ODOT Region 1 Portland, OR 48 4-2-08 Happy Hour Social gathering of the members and guests. Rogue Brewing, Portland TBD 4-8-08 April - Joint meeting with WTS Speakers scheduled: Gail Achterman, Chair of the Oregon Transportation Commission, and Richard Ford, Chair of the Washington State Transportation Commission University Place, Portland, OR TBD 5-9-08 Joint meeting with Oregon Traffic Control Devices Committee (OTCDC) This end of the year meeting will include announcement of the newly elected Oregon Section officers and will include a presentation on the TriMet Commuter Rail called WES (Westside Express Services) scheduled for completion in fall 2008. Hayden  s Grill, Tualatin, OR TBD", "2014 2013 Assets Current assets: Cash and cash equivalents $  16,091 $  21,903 Restricted cash 6,666 3,404 Accounts receivable, less allowance for doubtful accounts of $1,416 and $1,479 at June 30, 2014 and December 31, 2013, respectively 82,634 59,574 Inventories 116,872 119,477 Prepaids and other current assets 18,826 14,415 Deferred income taxes 9,030 10,551 Total current assets 250,119 229,324 Property, plant and equipment, net of accumulated depreciation of $39,965 and $39,007 at June 30, 2014 and December 31, 2013 respectively 70,924 74,558 Land rights, net 4,154 4,244 Deferred costs 18,364 18,732 Finance receivables from related parties 1,915 Intangible assets, net of accumulated amortization of $861 and $837 at June 30, 2014 and December 31, 2013, respectively 2,826 2,993 Deferred income taxes, long-term 7,772 7,758 Other long-term assets 1,707 1,741 Total assets $  355,866 $  341,265 Liabilities and Shareholders' Equity Current liabilities: Short-term loans and current portion of long-term debt $  138,711 $  122,840 Accounts payable 103,835 105,742 Accrued expenses and other current liabilities 59,208 62,539 Total current liabilities 301,754 291,121 Long-term debt, net of current portion 5,442 7,553 Income taxes payable, long-term 7,410 7,043 Legal settlements, net of current portion 31,232 30,941 Other long-term liabilities 512 427 Total liabilities 346,350 337,085 Commitments and contingencies Shareholders' equity: Common stock, CHF 1.00 par value; 41,107 shares authorized; 20,553    issued and outstanding at June 30, 2014 and December 31, 2013 22,048 22,048 Additional paid-in capital 2,553 901 Accumulated other comprehensive income 13,237 13,721 Retained deficit (28,322) (32,490) Total shareholders' equity 9,516 4,180 Total liabilities and shareholders' equity $  355,866 $  341,265", "Three months ended June 30, Six months ended June 30, 2014 2013 2014 2013 Net sales $  112,464 $  111,157 $  213,581 $  201,451 Cost of goods sold 86,953 84,150 163,283 153,609 Gross profit 25,511 27,007 50,298 47,842 Selling, general and administrative expenses 20,433 16,609 37,396 31,179 Litigation settlements 90 190 Operating income 4,988 10,398 12,712 16,663 Other expense (income): Interest expense 2,319 1,598 4,626 2,991 Interest income (38) (166) (65) (264) Foreign exchange (gains) losses, net (633) 2,231 (1,307) 4,637 Income before income taxes 3,340 6,735 9,458 9,299 Income tax expense 1,387 2,184 3,584 3,807 Net income $  1,953 $  4,551 $  5,874 $  5,492 Other comprehensive income: Foreign currency translation adjustments 172 613 (484) 1,829 Comprehensive income $  2,125 $  5,164 $  5,390 $  7,321 Net income per share-basic and diluted $  0.10 $  0.22 $  0.29 $  0.27", "Six months ended June 30, 2014 2013 Cash flows from operating activities: Net income $  5,874 $  5,492 Adjustments to reconcile net income to net cash used in operating      activities: Depreciation and amortization 4,367 3,955 Deferred income tax expense (benefit) 1,460 (600) Share-based compensation expense 606 Loss on disposal of equipment 114 Changes in operating assets and liabilities: Accounts receivable (24,713) (10,790) Inventories 2,382 (30,397) Prepaid expenses and other assets (1,054) (2,475) Accounts payable 2,773 20,727 Accrued and other liabilities (4,095) (5,668) Net cash used in operating activities (12,286) (19,756) Cash flows from investing activities: Purchases of property, plant and equipment (6,025) (6,162) (Increase) decrease in restricted cash (3,306) 76 Repayment of related party finance receivables 209 422 Other investing activities, net 59 2 Net cash used in investing activities (9,063) (5,662) Cash flows from financing activities: Borrowings under foreign short-term bank loans 88,420 79,921 Repayments of foreign short-term bank loans (80,222) (66,426) Borrowings on line of credit agreement, net 7,971 3,847 Borrowings of long-term debt 588 Repayments of long-term debt (341) (124) Payment of related party finance liability (124) (139) Payment of debt issuance costs (701) Payment of deferred offering costs (40) Payment of contingent consideration (450) Net cash provided by financing activities 15,551 16,629 Effect of exchange rate changes on cash and cash equivalents (14) 313 Decrease in cash and cash equivalents (5,812) (8,476) Cash and cash equivalents at beginning of period 21,903 38,680 Cash and cash equivalents at end of period $  16,091 $  30,204", "Three Months Ended Six Months Ended June 30, 2014 March 31, 2014 June 30, 2013 June 30, 2014 June 30, 2014 Net income $  1,953 $  3,921 $  4,551 $  5,874 $  5,492 Adjustments: Interest expense, net 2,281 2,280 1,432 4,561 2,727 Income tax expense 1,387 2,197 2,184 3,584 3,807 Depreciation and amortization 2,177 2,190 2,003 4,367 3,955 EBITDA 7,798 10,588 10,170 18,386 15,981 Adjustments: Foreign exchange (gains) losses, net (633) (674) 2,231 (1,307) 4,637 Litigation settlements 90 100 190 Share-based compensation expense 606 606 Refund of U.S. Customs import tariffs (149) (149) Adjusted EBITDA $  7,712 $  10,014 $  12,401 $  17,726 $  20,618", "Transition Task: Prepared for the Project, Teaching to Fish (Build Tasks) Integrating OALCF Task Development within Ontarios Literacy Programs (2014)", "A: Find and Use Information B: Communicate Ideas and Information C: Understand and Use Numbers D: Use Digital Technology Task Group(s): A1: Read continuous text A2: Interpret documents B3: Complete and create documents C2: Manage time\nA2.2: Interpret simple documents to locate and connect information B3.2a: Use layout to determine where to make entries in simple documents B3.2b: Create simple documents to sort, display and organize information\nC2.1: Measure time and make simple calculations\nC4.1: Make simple comparisons and calculations D.2: Perform well-defined, multi-step digital tasks", "Performance Descriptors: see chart on last page\n Computer with a word processing program or spreadsheet program", "You have decided that returning to school is the best option for future employment.\nIt has been a long time since you attended classes and the timetable can be a bit overwhelming.\nThe scheduled classes are at different times in the day and you have to work out your travel time based on your class schedule.\nYou should never be late for a class or a job.", "Task 2: Using the Express and Regular bus schedules, locate the times that you will be catching the bus at the Downtown Terminal to arrive at the college on time for all classes.\nEnter the information\n follows the sequence of events in straightforward chronological texts\n follow simple, straightforward instructional texts\n identifies the main idea in brief texts\nA2.2  performs limited searches using one or two search criteria\n extracts information from tables and forms\n uses layout to locate information\n makes connections between parts of documents\n makes low-level inferences", "B3.2a  uses layout to determine where to make entries  begins to make some inferences to decide what information is needed, where and how to enter the information  makes entries using a limited range of vocabulary  follows instructions on documents", "B3.2b  follows conventions to display information in simple documents (e.g. use of font, colour, shading, bulleted lists) identifies parts of documents using titles, row and column headings and labels  sorts entries into categories  displays one or two categories of information organized according to content to be presented C2.1  recognizes values in number and word format  understands chronological order  understands and uses common date formats  reads time on analog and digital clocks  identifies and performs required operation  represents dates and times using standard conventions  measures time using common instruments, such as clocks, timers and stopwatches  chooses appropriate units of measurement (e.g. hours, minutes, seconds)  interprets and represents time using whole numbers, decimals (e.g. .25, .5) and simple common fractions (e.g. ,  hour)  follows apparent steps to reach solutions  uses strategies to check accuracy (e.g. estimating, using a calculator, repeating a calculation, using the reverse operation) C4.1  recognizes values in number and word format  understands numerical order  identifies and performs required operation  makes simple estimates  follows apparent steps to reach solutions  recognizes simple patterns  uses strategies to check accuracy (e.g. estimating, using a calculator, repeating a calculation, using the reverse operation)", "National Inquiry into Sexual Harassment in Australian Workplaces Australian Human Rights Commission Via online submission form.", "Dear Sir/Madam, We welcome the opportunity to provide feedback in relation to the National Inquiry into Sexual Harassment in Australian Workplaces.", "Please do not hesitate to contact me and my colleagues if we can further assist with the Commissions important work.", "Page\n2. The use of technology and social media to identify both alleged victims and perpetrators of workplace-related sexual harassment.\n5\n3. The drivers of workplace sexual harassment, including whether: some individuals are more likely to experience sexual harassment due to particular characteristics including gender, age, sexual orientation, culturally or linguistically diverse background, Aboriginal and/or Torres Strait Islander status or disability, and some workplace characteristics and practices are more likely to increase the risk of sexual harassment.\n5\n4. The current legal framework with respect to sexual harassment.\n6\ni. Positive obligation on employers 7\niv.\n6 month time limit on complaints 9\n6. The impacts on individuals and business of sexual harassment, such as mental health, and the economic impacts such as workers compensation claims, employee turnover and absenteeism.\n17", "Maurice Blackburn Pty Ltd is a plaintiff law firm with 32 permanent offices and 29 visiting offices throughout all mainland States and Territories.\nThe firm specialises in personal injuries, medical negligence, employment and industrial law, dust diseases, superannuation (particularly total and permanent disability claims), negligent financial and other advice, and consumer and commercial class actions.", "Maurice Blackburn employs over 1000 staff, including approximately 330 lawyers who provide advice and assistance to thousands of clients each year.\nThe advice services are often provided free of charge as it is firm policy in many areas to give the first consultation for free.\nThe firm also has a substantial social justice practice.", "Maurice Blackburn is grateful for the opportunity to contribute to this important inquiry, and congratulates the Australian Human Rights Commission (AHRC) on its instigation.", "Our experience and expertise in representing those who have fallen victim to the scourge of sexual harassment in the workplace affords us a unique view of the current system for handling complaints.\nThis includes observations on the various pieces of legislation which make up the current framework, the complaints and appeals processes, and the assistance available to victims.", "Maurice Blackburn is of the view that one of the significant failings of the current legislative scheme is the onus it places on victims to seek redress for the harm they have suffered, rather than placing a positive obligation on employers to prevent the harm occurring in the first instance.\nWe believe there should be enforceable sanctions against employers who fail in their duty to provide a safe workplace for their employees.", "We believe that it is important that the governing bodies of all organisations should be fully aware of the incidence of sexual harassment in their workplace, and that they should be required to report on the number of reported incidents of sexual harassment, as part of their reporting requirements to Workplace Gender Equality Agency (WGEA).", "We believe that the current legislated timeframe for making a complaint through AHRC is unworkable and out of step with other legislative provisions.\nIt should be amended to 6 years in line with other employment law jurisdictions.\nWe believe that the Australian Human Rights Commission Act 1986 (the AHRC Act) or regulations should be amended to expressly prescribe time frames for the scheduling of mediation conferences.", "We believe that other authorities, such as State and Territory Work, Health and Safety regulators, along with trade unions and consumer advocates, could and should have a greater role to play in addressing and stamping out workplace sexual harassment.", "Above all, we believe that the AHRC should be properly funded and fully staffed in order to fulfil its statutory objectives and enable it to more swiftly and robustly perform its vital role in resolving claims of sexual harassment in the workplace.", "In preparing this submission, Maurice Blackburn has engaged with a number of organisations such as NOW Australia and Unions NSW, who share our goal of preventing sexual harassment from occurring in Australian workplaces and securing justice for victims.\nSpecifically, Maurice Blackburn, NOW Australia and Unions NSW hosted a roundtable with union officials, politicians, barristers and labour lawyers, to facilitate a discussion about the most effective legislative reforms to secure justice for victims of sexual harassment.\nThese round table discussions allowed Maurice Blackburn to draw from the knowledge of other highly experienced professionals working in employment law and industrial relations, in formulating this submission.", "These key themes are explored in more detail in the following pages.\nWe also refer the AHRC to the joint statement submitted by over 100 organisations including Maurice Blackburn and the submission to this inquiry from Women Lawyers NSW, which addresses some of these matters in more detail (and with which representatives of Maurice Blackburn have been involved).", "Maurice Blackburn Responses to Terms of Reference.\n1. Online workplace-related sexual and sex-based harassment and the use of technology and social media to perpetrate workplace-related sexual and sex-based harassment", "Maurice Blackburn is concerned about the impacts that online workplace-related sexual and sex-based harassment is having on many Australians under the current, mostly unregulated on-line environment.", "We draw the AHRCs attention to the effects of exposure to such behaviours by those whose work, by necessity, involves interaction via social media platforms.", "In particular, we are concerned by the reports from journalists and those involved in the media about the prevalence and impacts of on-line workplace-related sexual and sex-based harassment.", "We believe that employers must be held accountable for creating a work environment that exposes their employees to the risk of this form of sexual harassment.", "We are aware that some employers in the media industry, for example, have expectations of their staff relating to their on-line inputs, and set key performance indicators in areas such as the number of hits a story receives.", "Journalists are also frequently expected by their employers to participate in on-line discussions that emanate from their story.\nSome employees have reported that employers expect them to express personal opinions in relation to on-line stories.\nWe are concerned that these forced interactions are exposing media professionals to online workplace-related sexual and sex-based harassment.", "We note the reporting of the Media, Entertainment and Arts Alliance (MEAA) on this matter: The lived experience of many MEAA members working in the media industry is of being regularly subjected to harassment, abuse and threats on social media.1 MEAA has written substantially on the topic, noting that their members have suffered diagnosable psychiatric injuries as a consequence of cyber abuse.", "1 Ref Media Entertainment and Arts Alliance submission to Legal and Constitutional Affairs References Committee inquiry into the adequacy of existing offences in the Commonwealth Criminal Code and of state and territory criminal laws to capture cyberbullying: https://www.aph.gov.au/DocumentStore.ashx?id=5590919d-ca1e- 4049-9834-44ab87e8bedc&subId=562289", "There appears to be clear differences in the impacts of interaction with the readership, between on-line and traditional media functions.\nThese include:\n Anonymity.\nReports suggest that anonymity may be a determining factor in whether on-line input is threatening, abusive or personal.\nIt seems probable that the ability to hide behind anonymity might be an enabler of on-line sexual harassment.\nJournalists, on the other hand, are encouraged to use their own names.\nThis inequality is concerning in the workplace context.\n Immediacy.\nResponding to on-line media does not encourage introspection or the tempering of language or behaviour.\n The perception that the rules are different on-line.\nThreats or harassment made online seem to be held to a different standard of accountability than if they were made via any other mechanism.\nSome of the current academic work around online disinhibition is worthy of exploration.", "We have long argued that a legislative framework is needed which incorporates:\n Regulation and criminal sanctions holding the behaviours of abusers, employers and carriage services to account, and\n A civil regime through which victims and survivors of online abuse can access legal tools to allow them to seek relief and damages.", "This will necessitate criminalising particularly nefarious behaviours, and then providing the relevant police and regulatory services with the resources to successfully prosecute people engaging in sexual harassment through on-line platforms.", "We believe that, for this to have the required deterrent effect, it is important that all those who cause, enable or expose people to on-line sexual harassment should be held to account, and this includes employers, and social media platforms, as well as those who generate and distribute the abusive material.", "We recognise, however, that given the scope and pervasiveness of on-line sexual harassment, no regulator or law enforcement agency, no matter how well equipped, will be in a position to effectively deal with every case, let alone every extreme case.\nHence the need for a concurrent civil process which provides citizens with the tools required to achieve appropriate redress.", "Maurice Blackburn believes Australia needs a civil / criminal legislative framework which could ensure:\n That breaches, can be investigated by a statutory body established under the Act, and failing that, the courts.\n That the statutory body can order that offending materials be removed from an on-line platform, and require a correction and/or an apology.\n That the frameworks allows for the release of the identity of anonymous abusers.\n That on-line sexual harassment is criminalised where:", "o the abuser intends a digital communication to cause harm, o a person would reasonably expect the person in the position of the victim to be harmed, and o the individual suffers serious emotional distress.", "Our submissions in response to ToR 1: Maurice Blackburn submits that changes to the regulatory environment in relation to online workplace-related sexual and sex-based harassment must include enforceable sanctions against employers who fail in their duty to provide a safe workplace for their employees.", "Maurice Blackburn encourages the AHRC to consider ways that employers can assist in creating a workplace where exposure to discussion and engagement via social media platforms does not impact an employees right to a safe work environment.", "We encourage the AHRC to reimagine how a criminal code and a civil regime to combat on- line sexual harassment in Australia might be implemented.", "We submit that any discussion on criminality and penalties must also recognise that it is important to give individuals the legal tools to allow them to:\n Seek injunctive relief and damages from the perpetrators of on-line sexual harassment, and\n Seek injunctive relief and damages from the providers and facilitators of online forums where the provider or facilitator has failed to discharge a duty to monitor and protect users.\n2. The use of technology and social media to identify both alleged victims and perpetrators of workplace-related sexual harassment", "No response to this Term of Reference\n3. The drivers of workplace sexual harassment, including whether: some individuals are more likely to experience sexual harassment due to particular characteristics including gender, age, sexual orientation, culturally or linguistically diverse background, Aboriginal and/or Torres Strait Islander status or disability, and some workplace characteristics and practices are more likely to increase the risk of sexual harassment.", "Maurice Blackburns staff regularly assist clients who have experienced sexual harassment or sex-based discrimination.", "ABS data2 suggests that one in two women (53% or 5 million) and one in four men (25% or sexual harassment, and the proportion of women experiencing sexual harassment in the last 12 months has increased from 15% in 2012 to 17% in 2016.\n2.2 million) have experienced sexual harassment during their lifetime.\nIn the last 12 months, one in six women (17% or 1.6 million) and one in eleven men (9.3% or 836,700) experienced", "2https://www.humanrights.gov.au/publications/chapter-4-nature-sexual-harassment-australian-workplaces-sexual- harassment-serious", "We are mindful of the figures which the AHRC recently published3 which show that:\n In the last 12 months, 23% of women and 16% of men have experienced sexual harassment at work;\n Women of colour, young adults (18-24), those with a disability, and LGBTI people are particular targets of sexual harassment4;\n In the last 5 years, 81% of employees in the information, media and telecommunications industry having been sexually harassed;\n 40% of workplace sexual harassment incidents were witnessed by at least one other person, and in the majority of cases (69%) the witness did not intervene;\n Fewer than one in five people made a formal report or complaint about sexual harassment in the workplace; and\n Almost one in five people who did report sexual harassment were either labelled a trouble-maker; ostracised, victimised or ignored by colleagues; or resigned.", "In our and their experience, sexual harassment is largely about power and so it will be more frequently visited on the most vulnerable including those in precarious employment and those who cannot take the great risk of speaking out about abuse.\nThe trauma caused by sexual harassment cannot and must not be underestimated.\n4. The current legal framework with respect to sexual harassment.", "There are a number of areas within the current legal framework where Maurice Blackburn believes that adjustment is required in order to achieve the goals of this inquiry.", "In the section below, we have separated these into a number of discrete areas of law for discussion:\ni. Positive obligation on employers;\nii.\nHealth and safety;\niii.\nExpanding company reporting requirements;\niv.\n6 month time limit on complaints;\nv. Damages; and", "3 Australian Human Rights Commission, Everyones Business: Fourth National Survey on Sexual Harassment in Australian Workplaces (2018).", "4 Australian Human Rights Commission, Change the Course: National Report on Sexual Assault and Sexual Harassment at Australian Universities (2017).", "Sexual harassment in the workplace has been prohibited in Australia since the passing of the Sex Discrimination Act 1984 (Cth) (SDA). However, the persistent prevalence of sexual harassment within Australian workplaces since that time suggests that the current legislation has failed in preventing this kind of conduct.", "Maurice Blackburn is of the view that one of the significant failings of the current legislative scheme is the onus it places on victims to seek redress for the harm they have suffered, rather than placing a positive obligation on employers to prevent the harm occurring in the first instance.", "The current legislative scheme requires victims of sexual harassment to take the step of making a complaint before they are able to pursue a remedy in relation to the unlawful harassment (the Individual Complaint Model)5.", "This means that an individual, who may (and often does) have limited access to the law, is obliged to take the step of filing a complaint with the AHRC, in order to seek redress.\nThis process can be burdensome and difficult to navigate without legal advice.\nWe will return to our concerns regarding the current system in our discussion on the Complaints Process.", "It can also be daunting for victims who are emotionally distressed, unfamiliar with legal processes, fearful of reprisal, and who are unsure of their legal rights.\nFurther, women who are of a low economic status, who are from migrant backgrounds, or who have limited career mobility are among the most vulnerable groups6.", "Indeed, it is the persistent and increasingly low rates of reporting7 that fundamentally undermines the effectiveness of the Individual Complaint Model8.\nIn the Fourth National Survey on Sexual Harassment in Australian Workplaces (the Fourth Report), the AHRC found that only 17 percent of people who had experienced sexual harassment in the workplace reported the behaviour9.", "That means that in 83 percent of cases, the victims did not make a complaint for a whole host of reasons.\nThese statistics demonstrate that in the vast majority of cases the current legislative scheme has both failed to prevent the conduct through deterrence, and has failed to address the conduct through providing victims with access to an adequate remedy.", "Under the current scheme, an employers obligation to take reasonable steps to prevent sexual harassment only becomes relevant where they are defending a claim of sexual harassment - that is, after the harassment and the harm have already occurred10.", "Specifically, under s106 of the SDA an employer can escape vicarious liability for sexual harassment, where it can establish that it took all reasonable steps to prevent the sexual harassment from occurring11.", "5 Standing Committee on Legal and Constitutional Affairs, Parliament of Australia, Half Way to Equal: Report of the Inquiry into Equal Opportunity and Equal Status for Women in Australia (1992) (Halfway to Equal Report).", "6Elyse Shaw, Ariane Hegewisch, M. Phil and Cynthia Hess, (2018) Sexual Harassment and Assault at Work: Understanding the Costs Institute for Womens Policy Research.", "7 Everyones business: Fourth National Survey on Sexual Harassment in Australian Workplaces, p63.\n8 Paula McDonald, Sara Charlesworth, Tina Graham (2015) Asia Pacific Journal of Human Resources Developing a framework of effective prevention and response strategies in workplace sexual harassment, Vol 53, Issue 1.\n9 Everyones business: Fourth National Survey on Sexual Harassment in Australian Workplaces, p63.\n10 S106 of the Sex Discrimination Act 1984 (Cth).", "While there is no definition of reasonable steps contained in the SDA, reasonable steps may include having an internal policy that prohibits sexual harassment, conducting training on what constitutes sexual harassment and dealing with sexual harassment complaints in an appropriate manner.", "Maurice Blackburn is of the view that the burden currently borne by victims to enforce their rights should be more evenly shared between victims, employees, and employers.", "Maurice Blackburn submits that rather than the obligation to take reasonable steps being used to prevent sexual harassment being used as a defence to liability, the SDA should impose a positive obligation on employers to take all reasonable steps to prevent sexual harassment occurring in the workplace, whether an incident has occurred or not.", "This positive obligation would work in a similar way to, and in conjunction with, the statutory obligation an employer has to ensure the health and safety of its employees when they are at work in accordance with relevant workplace health and safety legislation.", "We note that this was recommended by the HREOC in their submission to the Senate Inquiry on the Effectiveness of the Sex Discrimination Act, in 200812 but was not adopted.\nWe are of the view that it should have been.", "The duty proposed in the previous section should not detract from the current and often ignored responsibility of safety regulators in each State and Territory to investigate and prosecute breaches of health and safety legislation.", "In our view, it should be made abundantly clear, via legislative reform or through delegated legislation, that regulators are required to investigate sexual harassment complaints given the health and safety implications of same.", "We acknowledge that regulators are chronically understaffed and underfunded in many States and Territories and would encourage the establishment of a properly funded discrete directorate within WHS regulators aimed at investigating risks to health and safety arising from sexual harassment.", "In order to reduce the load on regulators, trade unions should also have the ability to prosecute for health and safety breaches reinstated where such rights have been removed.", "It has been argued by the leading academics in this space that the prevention of sexual harassment is enhanced if senior managers in a workplace understand what behaviour constitutes sexual harassment and that there are consequences for the business if it occurs13.", "Maurice Blackburn considers the elimination of sexual harassment against women in the workplace to be an essential component of achieving gender equality more broadly.", "12 Submission of the Human Rights and Equal Opportunity Commission to the Senate Legal and Constitutional Affairs Committee, Inquiry Into The Effectiveness Of The Sex Discrimination Act 1984 (Cth) In Eliminating Discrimination And Promoting Gender Equality, 2008, pg145.", "Businesses are already required by legislation to report on key gender equality indicators to WGEA annually.\nWe are of the view that as part of this reporting, businesses should also be required to report on the number of reported incidents of sexual harassment.", "Further, reporting to Board and senior management level (in smaller business) must also be mandated if real cultural change is to occur.", "Whilst we acknowledge that the figure reported will not be representative of the true number of instances of sexual harassment given the very low reporting rates, we are of the view that this measure would create an important incentive for large businesses, and their senior managers, to take their obligation to prevent sexual harassment seriously.", "Following a Joint Parliamentary Committee inquiry into freedom of speech (JPC Inquiry) in April 2017 the Human Rights Legislation Amendment Bill (2017) (the Amendment) was passed by both houses of Parliament.", "One of the most significant effects of the Amendment was to amend s46PH of the AHRC Act so that a complaint, including a complaint in relation to sexual harassment, can be terminated by the President of the AHRC if it is lodged more than 6 months after the alleged events took place.", "The effect of this change is significant.\nWhile this time limit does not operate in the same way as a statutory limitation period does, the effect of a decision of the President to terminate the complaint is that a complainant loses access to the confidential mediation process facilitated by the AHRC.", "The benefit of having access to the AHRCs mediation process is that it allows victims of sexual harassment, whom typically have restricted access to the law, the opportunity to engage in a relatively low cost, less adversarial dispute resolution process.", "Maurice Blackburn submits the Amendment should be repealed and that the time for making complaints should be amended to 6 years in line with other employment law jurisdictions.", "This submission is made for the following reasons:\n There is no sound policy reason for imposing the time period on complaints;\n A six-month time period is out of step with other Australian employment law jurisdictions; and\n Reducing access to an informal, low-cost dispute resolution process has a negative impact on the efficient resolution of complaints.", "These are elaborated upon below:\nThere is no sound policy reason for the new time limit.\nAt the time the Amendment was passed, there was no clear policy rationale put forward by the legislature for the change to the time limit, save for the apparent need to mitigate unmeritorious or vexatious claims being made14.\nThe JPC Inquiry recommended that the AHRC adopt time limits for the processes related to complaint handling activities at the initial assessment of the complaint15.\nHowever, this recommendation did not extend to reducing the time limit a complainant has to lodge a complaint16.\nIndeed, the JPC Inquiry made a number of recommendations in relation to expanding the Presidents power to terminate a complaint pursuant to s46PH of the Act. Notably, none of these recommendations related to reducing the time limit available to complainants for lodging a complaint.\nThere is no evidence which suggests claims that are made more than six months after the alleged events took place are less meritorious than those that are made before this time period.\nIn fact, to the contrary, it is well documented that victims of sexual harassment may face a number of hurdles in bringing a complaints in short time periods for a number of reasons, including the emotional and psychological impact the conduct often has them.17\nOf the 17 percent of people who made a complaint to their supervisor, the majority of complaints were made shortly after the events occurred.\nThe statistics in relation to the timing of reporting sexual harassment were set out comprehensively by the AHRC in the Fourth Report, and are illustrated in the graph below.\n14 Explanatory Memorandum, Human Rights Legislation Amendment Bill 2017, para 116-118.\n15 Recommendation 8 of Report Freedom of speech in Australia Inquiry into the operation of Part IIA of the Racial Discrimination Act 1975 (Cth) and related procedures under the Australian Human Rights Commission Act 1986 (Cth) 16Recommendation 8 of Report Freedom of speech in Australia Inquiry into the operation of Part IIA of the Racial Discrimination Act 1975 (Cth) and related procedures under the Australian Human Rights Commission Act 1986 (Cth).\n17 See for example https://www.nytimes.com/2018/09/18/us/kavanaugh-christine-blasey-ford.html", "Maurice Blackburn is of the view that these statistics demonstrate two things:\n Given that underreporting remains high, it may be the case that the majority of victims require more than 6 months to make a complaint; and\n It is simply not the case that a large number of victims report sexual harassment a long time after it has occurred, so as to justify the imposition of the 6 month time restriction as a deterrence for a large number of unmeritorious complaints.", "This means that in addition to there being no sound policy reason for the time period for lodging sexual harassment complaints with the AHRC being reduced to 6 months, there is a strong case for the time period being extended beyond the 12 month period that is placed on complaints in different jurisdictions, and which existed before the Amendment was enacted.", "For this reason, the time limit imposed by s46PH(b) of the AHRC Act should be abolished, especially with respect to sexual harassment complaints.", "We are of the view that the 6 year time limitation period that applies to other kinds of discrimination matters in the Fair Work jurisdiction should apply to complaints made by the AHRC, particularly for sexual harassment complaints.", "Additionally, there are sufficient grounds under s46PH of the AHRC Act that allow the President to terminate a complaint where the complaint is without merit or is better dealt with in another jurisdiction, without the inclusion of s46PH(b).", "Indeed, s46PH(c) provides the President with very broad powers to terminate a complaint in circumstances where having regard to all the circumstances, that an inquiry, or the continuation of an inquiry, into the complaint is not warranted.", "We submit that if there is a legitimate concern that a complaint was without merit for any reason, the President is still able to exercise his/her power to terminate it under this provision.", "The 6 month time limit is particularly short when compared with similar jurisdictions that deal with discrimination or employment law issues.", "By way of comparison, the discrimination provisions of the Fair Work Act 2009 (Cth) allow discrimination claims to be dealt with by the Fair Work Commission provided that they are brought within 6 years of the alleged events occurring, where the complaint does not involve dismissal.", "Further, the Anti-Discrimination Act 1975 (NSW), only allows the President of the Anti- Discrimination Board to terminate a complaint if it is brought more than 12 months after the alleged events occurred.", "Maurice Blackburn is of the view, that 12 months is a particularly short time period, but 6 months is simply unjustified.", "The damages awarded in sexual harassment matters have historically been significantly lower than comparable jurisdictions in which an applicant suffers an illness as a result of unlawful conduct.", "While this trend was disturbed somewhat after the decision in Richardson v Oracle Corporation Australia Pty Ltd18 (Oracle), where the complainant was awarded $130,000.00 the detrimental impact of historically low awards of damages should not be underestimated.", "Indeed, at the time of writing, there is an absence of a significant body of case law which supports the approach taken by the Federal Court of Appeal, in Oracle.\nWhile subsequent cases have referenced Oracles emphasis on changing community standards to support the rationale behind increasing awards of damages, this rationale has not been reflected in the quantum awarded to complainants.", "Further, our experience in assisting clients navigate the legal process with respect to sexual harassment complaints suggests that the low awards of damages has an additional deterrent effect when a complainant is making a decision to file a complaint with the AHRC or commence litigation.", "While damages are assessed in a similar way to tortious common law claims, given claimants rights emerge from statute, there may be scope for providing more specific statutory guidance as to the appropriate quantum in respect of awards of damages.", "For example, it has been argued that an increased focus on exemplary damages, rather than compensatory damages would better reflect the moral wrong caused by the conduct and have a greater deterrent effect on perpetrators19.", "One possible reform to remedy this issue would be the insertion of statutory criteria to be taken into account by the Courts when determining an award of damages.", "In NSW there is a statutory cap of $100,000.00 pursuant to s108(7) of the Anti-Discrimination Act 1977 (NSW) (the ADA). In Western Australia there is a statutory cap of $40,000.00 on damages pursuant to s s127(b)(i) of the Equal Opportunity Act 1984 (WA).", "Given average weekly earnings of women have increased eight times since the enactment of the ADA, the failure of the legislature to increase the caps over time, has rendered the quantum of damages recoverable pursuant to these caps manifestly inadequate in both deterring offenders and compensating victims for harm they have suffered20.", "Further, the effect of the statutory caps is that only the very worst examples of sexual harassment attract an award of damages of this magnitude.\nMaurice Blackburn is of the view that statutory caps on damages under state legislation should be abolished to reflect the federal jurisdiction.", "In addition to the limitations of the statutory framework set out above, from our experience, the Individual Complaints System itself can be ineffective at achieving a just result for complainants.", "Our primary and overriding submission in relation to the Individual Complaints System is that it is paramount that the AHRC be properly funded and fully staffed in order to fulfil its statutory objectives.", "Below we have identified three additional issues which impact the efficacy of the Complaints Process.\nThey are related to:\n Scarcity of data on mediations;\n Employer tactics; and\n The mediation process", "It should be noted that there have been very few Australian studies which have examined the outcomes of the mediation process with respect to anti-discrimination matters, and even less with respect to sexual harassment matters specifically.\nThis is largely due to 19 Therese MacDermott (2015) Reassessing Sexual Harassment: It's time Alternative Law Journal, 40(3), 157.\n20 Harassment compensation caps outdated in #MeToo era the lack of data available given claims that are settled are often the subject of confidentially terms21 or settled outside (including after) the AHRC process and not reported.", "The scarcity of data and the deficiencies in the currently published data have led to a situation where a significant barrier to commencing proceedings or filing a complaint is the inaccuracy of the quantum of reported settlements.", "It is our experience that men and women who have experienced sexual harassment in the workplace will obtain settlements well into the 6 figure mark as a result of mediation or private negotiations.", "Despite this, the data reported on the AHRC website (which appears to have last been updated in 2016), together with, a study conducted by Worley, Charlesworth and Macdonald22 found that during mediation financial compensation was paid in 72 percent of cases they examined, with the median quantum being $7000.00.", "Better settlement data (including on post mediation outcomes) needs to be obtained, maintained and published by the AHRC so that complainants can understand that there are available remedies which sound in real compensation being negotiated that may go some way to compensating the victims of sexual harassment for the hurt, humiliation, distress and financial losses that they have suffered.", "In addition, a tactic commonly used by employers to drive up complainants costs or to discourage commencement in court is to make very low offers at the mediation stage, irrespective of their risk exposure.\nThis is done on the assumption that complainants cannot afford to pursue the complaints process past mediation.", "Given there is no risk of the imposition of a fine or a penalty, there is little incentive for employers to make reasonable settlement offers early in the mediation stage.", "Accordingly, Maurice Blackburn is of the view that the SDA should be amended so that in addition to compensation, penalties are also payable by respondents who are found liable for sexual harassment.", "Penalties are a common feature of the industrial relations landscape in Australia and would have a necessary deterrent effect.\nThey would also overcome the challenge many complainants face (especially those who are low paid and can therefore expect a lower award of damages for economic loss) of having little leverage during the mediation process, especially if they are not financially placed to engage in lengthy and costly litigation.", "21 Worley, Charlesworth and McDonald (2013) Why do some sexual harassment complaints settle while others dont?\nAlternative Law Journal 38(2), 96-102.", "The study conducted by Worley, Charlesworth and Macdonald23 found that a number of factors influenced the outcome including differences in the manner in which mediators conducted the mediation, whether the complainant had found another job and of course the level of harm and distress they had suffered.", "It is our observation that the approach taken to mediation in the AHRC is for a mediator to take a light touch and express no view as to the merits of a claim or, conversely, as to the potential liability and risk of a respondent to a claim.\nIn our view, a more robust approach to mediation should be adopted in the interests of increasing settlements at mediation.", "Process after Complaint lodged Our experience assisting complainants in the mediation process facilitated by the AHRC, is that there is an unsatisfactorily slow rate at which complaints are dealt with.", "This results in complainants feeling fatigued and worn down by the process.\nIn most instances, our experience has been that it takes between 3 and 12 months to have a complaint scheduled for mediation and sometimes months to even have a matter allocated to a mediator.\nIn this time, complainants find it difficult to move on with their lives and take steps toward overcoming the trauma they have suffered as a result of the harassing behaviour.", "In order to address this concern, Maurice Blackburn is of the view that the AHRC Act should be amended to expressly prescribe time frames for the scheduling of mediation conferences.\nThis would allow complainants to have their complaint dealt with in a reasonable period of time.", "While we acknowledge that a level of informality and flexibility is highly desirable in dealing with discrimination and sexual harassment matters, Maurice Blackburn is of the view that a higher level of certainty with respect to how the mediation conferences are conducted should be given to complainants.", "Currently, participation in the mediation process with the AHRC is voluntary for respondents.\nIn our observation this leads to claimants being further traumatised by the actions of their employers - who either do not file a response or do not attend mediation or prevaricate regarding same.", "Maurice Blackburn is of the view that in order to encourage respondents and employers to participate in the mediation process in meaningful, constructive and useful way, the AHRC Act should be amended to make it mandatory for respondents to attend the mediation conference and to file a reply document in a specified period of time.", "Maurice Blackburn further submits that the AHRC should consider the establishment of a victim advocate role within the AHRC to represent individuals at mediations where those individuals cannot achieve access to justice.\nWe recognise that this service would need to be subject to some form of means test and/or other criteria (by way of example - refugee status, or ATSI, CALD or LGBTQI status).\nWhilst being potentially invaluable for victims of workplace sexual harassment, this may have broader carriage within AHRC.", "Further, it is our view that claimants should be able to elect to bypass the AHRC and proceed straight to Court.\nThe decision to take such a bold step would necessarily be influenced by the anticipated attitude of an employer and the length of time likely taken to get a mediation at the AHRC.", "Our submissions in response to ToR 4: That the SDA should impose a positive obligation on employers to take all reasonable steps to prevent sexual harassment occurring in the workplace, whether an incident has occurred or not.", "That State and Territory WHS authorities be explicitly authorised to investigate and impose sanctions on employers who have breached their duty to provide safe and without risk workplaces, particularly in the context of sexual harassment.", "That State and Territory WHS authorities be appropriately resourced to investigate and prosecute risks to health and safety arising from sexual harassment.", "That trade unions be granted the authority to prosecute for health and safety breaches reinstated where such rights have been removed.", "That the AHRC recommend a process for formally requiring that reporting of sexual harassment claims and statistics be made to the board of the defined entity and to an external organisation.", "That businesses should also be required to report on the number of reported incidents of sexual harassment, as part of their reporting requirements to WGEA.", "That the Human Rights Legislation Amendment Bill (2017) should be repealed and that the time for making complaints should be amended to 6 years in line with other discrimination jurisdictions.", "That the time limit imposed by s46PH(b) of the AHRC Act should be abolished, especially with respect to sexual harassment complaints.", "That AHRC explore the insertion of statutory criteria to be taken into account by the Courts when determining an award of damages.", "That the SDA should be amended so that in addition to compensation, penalties are also payable by respondents who are found liable for sexual harassment.", "That the AHRC Act should be amended to expressly prescribe time frames for the scheduling of mediation conferences.", "That the AHRC Act should be amended to make it mandatory for respondents to attend the mediation conference and to file a reply document within a specified period of time.", "That AHRC consider the establishment of a victim advocate role within the AHRC to conduct mediations for those who cannot achieve access to justice.", "That a complainant be given the right to elect to bypass the AHRC and proceed straight to court.\n5. Existing measures and good practice being undertaken by employers in preventing and responding to workplace sexual harassment, both domestically and internationally.", "No response to this Term of Reference\n6. The impacts on individuals and business of sexual harassment, such as mental health, and the economic impacts such as workers compensation claims, employee turnover and absenteeism.", "It is our experience that victims of sexual harassment will suffer some form of mental health effect (including but not limited to a formal diagnosis of depression, anxiety, adjustment disorder or post-traumatic stress disorder).\nThe effects of these illnesses are lifelong and will be felt not just by a victim but by their loved ones.", "In our observation, the trauma inflicted by sexual harassment is rarely transient and can have flow on effects for the duration of a persons working life.", "This will often play out by an individual having to take sick leave or make a workers compensation claim given the effect of their health.\nIn many circumstances, it will impair a persons ability to work.\nIn the most serious of cases, involving sexual assault, some of our clients have needed to be institutionalised and their treating medical practitioners have indicated that they may never work again (or may never return to their chosen career) or may only ever work reduced hours.", "Of course, the effects of this trauma on entire families cannot be underestimated with many of our clients reporting a loss of enjoyment of life and the inability to interact with loved ones including children.", "In our view, prevention is key.\n7. Recommendations to address sexual harassment in Australian workplaces.", "Maurice Blackburn makes the following recommendations:\n1. That changes to the regulatory environment in relation to online workplace-related sexual and sex-based harassment must include enforceable sanctions against employers who fail in their duty to provide a safe workplace for their employees.\n2. That AHRC should consider ways that employers can assist in creating a workplace where exposure to discussion and engagement via social media platforms does not impact an employees right to a safe work environment.\n3. That AHRC investigate how a criminal code and a civil regime to combat on-line sexual harassment in Australia might be implemented.\n4. That any discussion on criminality and penalties designed to combat on-line sexual harassment must also recognise that it is important to give individuals the legal tools to allow them to:\n Seek injunctive relief and damages from the perpetrators of on-line sexual harassment, and\n Seek injunctive relief and damages from the providers and facilitators of online forums where the provider or facilitator has failed to discharge a duty to monitor and protect users.\n5. That the SDA should impose a positive obligation on employers to take all reasonable steps to prevent sexual harassment occurring in the workplace, whether an incident has occurred or not.\n6. That State and Territory WHS authorities be explicitly authorised to investigate and impose sanctions on employers who have breached their duty to provide safe and without risk workplaces, particularly in the context of sexual harassment.\n7. That State and Territory WHS authorities be appropriately resourced to investigate and prosecute risks to health and safety arising from sexual harassment.\n8. That trade unions be granted the authority to prosecute for health and safety breaches reinstated where such rights have been removed.\n9. That the AHRC recommend a process for formally requiring that reporting of sexual harassment claims and statistics be made to the board of the defined entity and to an external organisation.\n10.\nThat businesses should also be required to report on the number of reported incidents of sexual harassment, as part of their reporting requirements to WGEA.\n11.\nThat the Human Rights Legislation Amendment Bill (2017) should be repealed and that the time for making complaints should be amended to 6 years in line with other discrimination jurisdictions.\n12.\nThat the time limit imposed by s46PH(b) of the AHRC Act should be abolished, especially with respect to sexual harassment complaints.\n13.\nThat AHRC explore the insertion of statutory criteria to be taken into account by the Courts when determining an award of damages.\n14.\nThat the SDA should be amended so that in addition to compensation, penalties are also payable by respondents who are found liable for sexual harassment.\n15.\nThat the AHRC Act should be amended to expressly prescribe time frames for the scheduling of mediation conferences.\n16.\nThat the AHRC Act should be amended to make it mandatory for respondents to attend the mediation conference and to file a reply document within a specified period of time.\n17.\nThat the AHRC be properly funded and fully staffed in order to fulfil its statutory objectives.\n18.\nThat AHRC consider the establishment of a victim advocate role within the AHRC to conduct mediations for those who cannot achieve access to justice.\n19.\nThat a complainant be given the right to elect to bypass the AHRC and proceed straight to court.", "The following table provides a summary of the Oregon Sections membership, including grade and section dues.", "The membership committee continued its organizational captain membership program over the past year.\nThe program was designed to identify specific individuals within public and private organizations who might be interested in joining ITE or attending ITE functions.\nThe captains also assist with advertising meetings, recruiting new members, and promoting ITE.", "The Oregon Section maintained and enhanced the solid financial position that had been developed over the past several years.\nThe Oregon Section has signed up for online banking and uses a check card for most routine expenditures.\nPayments and account inquiries are processed faster and the overall number of reimbursement checks are reduced significantly.", "Most monthly functions for the 2007-08 fiscal year have either broken even or in the case of the January Technical Workshop have had a net income due to better than average attendance.\nThis can be attributed to interesting topics, user-friendly and informative web site as well as the hard work of Section officers and volunteers.\nThe remainder of this page summarizes the Sections 2007-2008 finances.", "Membership Dues: $4,405.00 Gross Income from Meetings: $6,455.00 Investment Income: $ 0.00 Advertising Income: $0.00 (None reported) Other Sources of Income: $5,238.54(Corporate sponsorship at Traffic Bowl) Golf Tournament: $5,455.00 (Corporate sponsorship $1,750.00 + $3,705.00 members) District 6 Student Fund: $3,000.00", "District 6 Meeting $1,311.66 Donations: $1,450 (Including Traffic Bowl prizes to student chapters) Internet Expenses: $234.00 Other Expenditures: $382.25 (Board Meetings) Golf Tournament: $5,754.82 Miscellaneous: $284.89 (PO box, election costs, etc.)", "Approximately 13 transportation related bills were passed by the Oregon Legislative Assembly during the 2007 session.\nThe topics of the bills vary widely, including issues such as expanding the use of photo radar and red light enforcement, various signing requirements, and gates for light rail pedestrian crossings.\nDetails on the bills are provided to the Oregon Section membership at", "The Oregon Section conducted six (6) general meetings and the summer golf tournament over the past year, as well as hosting Joint 2007 ITE District 6 annual meeting.\nThe general meetings included luncheons with speakers, joint-meetings with other professional societies, the annual traffic bowl, and a technical workshop.\nThe table below summarizes the general meetings conducted over the past year and those scheduled for the remainder of 2008.", "Sections newly elected officers were announced and a presentation on the Highway 25 emergency reconstruction efforts that followed a large storm on Mt.\nHood early 2007.", "Oregon ITE section hosted a very successful joint 2007 ITE District 6 Annual Meeting & Quad Conference in Portland.\nThis years annual meeting broke many previous records with over 500 meeting participants at the meeting.", "statewide transportation tour, and effort to build support for major investment in Oregons transportation system.", "University), Mike Coleman (City of Portland), Brian Ray, Beth Wemple (Kittelson and Associates), and Ken Crowley (Oregon DOJ).", "on the TriMet Commuter Rail called WES (Westside Express Services) scheduled for completion in fall 2008.", "The Section sponsored the annual January Technical Workshop on Tort, Liability, Ethics, and Professionalism in Transportation with featured speakers John Mason (Penn State University), Rayann Speakman (FHWA), Karen Dixon (Oregon State University), Mike Coleman (City of Portland), Brian Ray, Beth Wemple (Kittelson and Associates), and Ken Crowley (Oregon DOJ).\nThis workshop was well attended as with years past.", "The Student Liaison Committee had another successful year in attracting schools from the Pacific Northwest to compete in the Oregon Section's annual Traffic Bowl Competition.\nThe Traffic Bowl is a Jeopardy-based trivia contest where students must answer questions on a variety of traffic and transportation trivia.\nThis year the competition was held on November 15, 2007 at McMenamin's Edgefield just east of Portland, Oregon.", "This year we had 52 students from six universities attending the event.\nParticipating schools were:\n Portland State University\n University of Idaho\n University of Portland\n Oregon State University\n University of Washington\n Oregon Institute of Technology", "University of Portland took home the grand prize of bragging rights, a trophy and a $400 scholarship award.\nUniversity of Washington and Oregon Institute of Technology both received $300 for tying for second place.\nThe remaining three participating schools received a $150 participation award.\nAll of the student attendees received a free dinner at this event.\nIn order to offset the cost of the student meals and scholarships, several local companies donated funds to support student attendance.\nDonations were received from: Advanced Traffic Products, CH2M Hill, City of Gresham, City of Portland, Coral Sales Company, David Evans and Associates, DKS Associates, Group Mackenzie, HDR, IBI Group, JRH Engineering, Kittelson and Associates, Lancaster Engineering, NWS Traffic Engineering, Parametrix, Quality Counts, TrafStats, URS Corp, W&H Pacific, and Western Systems.\nThe Oregon Section has already secured the room for Traffic Bowl 2008 (November, 2008) at McMenamins Edgefield.", "This year, students continued to enjoy substantial discounts at Oregon ITE Section meetings ranging from free (Traffic Bowl) to $5 (Section Meetings) depending on the actual cost of the event and level of corporate sponsorship.", "This year the Oregon Section retained the domain name, www.oregonite.org.\nThe website remained very dynamic and was modified significantly to reflect the changing needs of the Section.\nThe web page includes information about meetings, activities, officer contact information, upcoming conferences, available jobs, and section news.\nThe site always has the current and upcoming meeting information posted, and on-line registration for Section meetings continued to be both popular and successful.\nIn addition, electronic download of the registration information were used to produce the registration list, name badges and written receipts for any specific event.\nThis form of registration has proven to be very effective and user friendly for members.", "The Oregon Section hosted its 18th annual ITE Golf Tournament at Quail Valley Golf Course on September 21, 2007.\nThe tournament drew 57 competitors from across the state.\nThe golf event was held at Oregon Golf Association (OGA) in Woodburn, Oregon.\nThis location is approximately 30 miles south of Portland.\nTurnout was good, exceeding last years attendance, and it was a fun and entertaining event.\nIn addition to volunteers, Lancaster Engineering, David Evans & Associates, DKS Associates, Quality Counts, Parsons Brinkerhoff, Inc., Kittelson & Associates, Inc., All Traffic Data Services, TrafStats, Western Systems and NW Signal sponsored the event.", "It is the Oregon Sections tradition to recognize the speaker at the Monthly Section Meetings and various other guests of the Section by presenting them with a token gift.\nUSB thumb drives printed with an Oregon ITE logo were purchased as speaker gifts this year, as were handmade coffee mugs with the Oregon ITE logo.", "The Oregon Section helped arrange the 2007 District 6 (now Western District) meeting that was held July 15 to 18 in Portland.\nThis meeting was combined with the Quad Conference to expand the reach of this event to our friends in Vancouver, BC.\nThe Quad meeting was originally scheduled to take place in 2008 in Portland, but the Oregon Section swapped meeting years with the Vancouver Island Section in order to better coordinate the district and quad meetings (a win-win situation for both Sections).", "The District 6 meeting was a huge success in that it attracted over 500 attendees.\nThe committee, chaired by Peter Koonce, was responsible for setting up a great technical and social event for the members of District 6.\nSome of the highlights include:\n PTOE/PTP/TSOS/TOPS Exam Offering\n James H. Kell Student Competition\n 36 Technical Sessions\n 2 Poster Sessions  Vendor Show  5 Technical Tours  Traffic Bowl  Awards Banquet (Bikes, Brews and Bohemia)  Golf Outing  Multi-Modal Brewery Tour  3 Guest Tours  Family Night at the Oregon Zoo", "The Oregon Section recognized several groups and individuals during 2007-08.\nThe Section provided over $1,450 in awards to various ITE Student Sections throughout the greater Northwest.\nThe awards granted over the past year are summarized below.\nAward Name: Traffic Bowl - First Place Award Recipient's Name: University of Portland Purpose of Award: To Encourage Student Participation in Oregon Section ITE Form of Award: $400 to Student Chapter", "Agent-based Computational Finance Blake LeBaron  Brandeis University April 21st, 2005: Comments still welcome!\nAbstract This chapter surveys research on agent-based models used in nance.\nIt will concentrate on models where the use of computational tools is critical for the process of crafting models which give insights into the importance and dynamics of investor heterogeneity in many nancial settings.", "International Business School, Brandeis University, 415 South Street, Mailstop 32, Waltham, MA 02453 - 2728, blebaron@brandeis.edu, www.brandeis.edu/blebaron.\nThe author is also a research associate at the National Bureau of Economic Research.\nThis is a preliminary draft for The Handbook of Computational Economics, vol.\nII,, edited by K. L. Judd and L. Tesfatsion.\nThe author is grateful to many people who have made comments on earlier drafts.\nThese include W. A. Brock, Cars Hommes, Leigh Tesfatsion, Frank Westerho, and two anonymous referees.\n3. Articial nancial markets", "Keywords: learning, evolutionary nance, nancial time series, asset pricing, ecient markets, behav- ioral nance, market microstructure, genetic algorithms, neural networks, articial nancial markets, evolutionary computation", "In the mid to later part of the 20th century, nance witnessed a revolution.\nThe advent of the ecient markets hypothesis, the capital asset pricing model, and the Black/Scholes options pricing formula put the eld on a new, solid scientic foundation.\nThis world was built on the assumption that asset markets were powerful computational engines, and were able to aggregate and process the beliefs and demands of traders, leaving in prices the full set of properly processed information currently available.\nAt the core of asset pricing, ecient market theories give a clean and compelling picture of the world which is as appealing to nancial economists as it is potentially unappealing to nancial practitioners.1 It is interesting to note that these foundations came with a very important computational dimension.\nThe early availability of large machine-readable data sets, and the computational power to analyze them, laid the critical foundation for this new nancial rigor.2 In agent-based computational models the computer is once again at the center of a change in thinking about nancial markets.\nThis time it is helping to pursue a world view in which agents may dier in many ways, not just in their information, but in their ability to process information, their attitudes toward risk, and in many other dimensions.", "Models in the realm of agent-based computational nance view nancial markets as interacting groups of learning, boundedly-rational agents.\nThe computer may or may not be a necessary tool to understand the dynamics of these markets.\nThis survey will concentrate on the cases where analytic solutions would be impossible, and computational tools are necessary.3 It is important to distinguish agent-based models from other more general heterogeneous agent models in nance, since the latter have been part of the eld for some time.4 In agent-based nancial markets, dynamic heterogeneity is critical.\nThis heterogeneity is represented by a distribution of agents, or wealth, across either a xed or changing set of strategies.\nIn principle, optimizing agents would respond optimally to this distribution of other agent strategies, but in general, this state space is far too complicated to begin to calculate an optimal strategy, forcing some form of bounded rationality on both agents and the modeler.\nIt is important to note that in these worlds bounded rationality is driven by the complexity of the state space more than the perceived limitations of individual agents.\nIt is also important to remember that the simplied rules of thumb used by agents do not suggest that the exercise is forcing some sort of simplied solution on the dynamics of the steady state or the model, 1This view is not far o the more general perspective on information dissemination in the economy as a whole put forth in Hayek (1945).", "3The survey by Hommes (2005) covers the more analytic heterogeneous agent models.\nAlso, the recent book by Levy, Levy & Solomon (2000) provides another survey of recent work in the eld.", "4See Tesfatsion (forthcoming 2005) for more extensive denitions of agent-based approaches in economics.", "or is presupposing that markets are not well represented by equilibrium rational stories.\nHowever, it is stressing that rules of thumb need to be built from a foundation of simple adaptive behaviors.", "Financial markets are particularly appealing applications for agent-based methods for several reasons.\nFirst, the key debates in nance about market eciency and rationality are still unresolved.\nSecond, nancial time series contain many curious puzzles that are not well understood.\nThird, nancial markets provide a wealth of pricing and volume data that can be analyzed.\nFourth, when considering evolution, nancial markets provide a good approximation to a crude tness measure through wealth or return performance.\nFinally, there are strong connections to relevant experimental results that in some cases operate at the same time scales as actual nancial markets.", "Academic nance has debated the issue of market eciency for some time.\nThe concept of market eciency has a strong theoretical and empirical backing which should not be ignored.5 On the theoretical side, the argument is that traders with less than rational strategies will disappear, and if prices contain any predictable components either in their own past series, or connected to fundamentals, the remaining rational investors will reduce these to zero.\nThis is very close to the evolutionary arguments put forth in both Alchian (1950) and Friedman (1953) for the evolution of rms and rational behavior in general.\nThis powerful idea still holds sway in much of the academic nancial world, and can be seen in papers such as Rubenstein (2001).\nAs appealing as this idea is, it is interesting to note that there never really has been a truly accepted dynamical process describing how market eciency comes about.\nThe second foundation for ecient market theories, supported by much of the early empirical work on nancial markets, is that markets are much more unpredictable than the world of the nancial practitioner suggests.6 In this early literature, the random walk model appeared to be a pretty good approximation for the movements of stock prices, and it can be argued that the same holds true today.\nWe know that markets are probably not completely unpredictable, but they still are very dicult to forecast.7 The early ideas of ecient markets were made more formal as modern tools of dynamic optimization were brought to bear on these problems.8 This led to an even stronger representation for nancial markets, the representative agent.9 This model formally connects asset prices to the beliefs of a single aggregate individual who can then be linked to various state variables of the macroeconomy.", "7It is also important to note that the radical idea that randomness was a good model for nancial prices goes back to the beginning of the 20th century in Bachelier (1900).", "9Constantinides (1989) is a good example describing the assumptions necessary to get a representative consumer in many cases.\nAlso, Kirman (1992) critically assesses the use of representative agents in many economic contexts.", "The theoretical parts of ecient markets ideas have been attacked for quite some time.\nOne of the most important questions for market eciency comes from Grossman & Stiglitz (1980).\nHere, agents have the choice of purchasing an information signal on a nancial asset.\nIn a perfectly ecient world with a small cost on the signal, no one would have an incentive to buy the signal.\nHowever, if no one bought the signal, how did the market get informationally ecient in the rst place?\nIt is interesting to note that many of the papers mentioned here, and in Hommes (2005), are based on the paradoxical structure of this model.\nMore recently, the literature on noise trading, [e. g., DeLong, Shleifer, Summers & Waldmann (1990)], introduced the important idea that risk averse rational types may not be able to take over the dynamics from less rational strategies, since they trade less aggressively because they are sensitive to the risk induced by the other traders.\nWe will see that this concept plays an important role in many of the computational models considered here.", "The attacks on the empirical side of market eciency have been more controversial.\nDuring the 1980s and 1990s evidence began appearing indicating weaknesses with the ecient market hypothesis and related equilibrium theories.\nThere was evidence of predictability at long horizons as in Campbell & Shiller (1988), and at shorter horizons as in Lo & MacKinlay (1988).\nOld prediction methods which had been previously discredited began to appear again.\nAn example of this was the use of moving average technical analysis rules as in Brock, Lakonishok & LeBaron (1992).\nAlso, connections between nancial markets and macro dynamics were called into question by papers such as Mehra & Prescott (1988) and Hansen & Singleton (1983).\nFinally, the single factor CAPM model was shown to be insucient in Fama & French (1992).\nPredictability alone did not mean the ecient market was dead.\nIndeed, in his later survey Fama (1991) is well aware that some studies had found some market predictability, but he correctly reminds us that predictability alone does not necessarily mean that markets are inecient since protable strategies may be bearing higher risk.10 Beyond simple predictability, there is a large range of empirical nancial puzzles which remain dicult to explain using traditional asset pricing models.\nAmong these are the overall level of volatility and long swings around fundamentals.11 Also, the equity premium, which measures the dierence between the real return on risky and riskless assets, is dicult to explain.12 This feature is directly connected to the failure of macro time series to connect well to nancial markets.\nSeries such as consumption are not volatile enough, and 10A good recent survey on this literature is Campbell (2000); see also, the textbook by Campbell, Lo & MacKinlay (1996).", "12This one feature has generated an extensive literature which is surveyed in Kocherlakota (1996) and more recently in Mehra (January/February 2003).", "do not comove with markets in a way that can justify the magnitudes of risk premia observed in nancial series.\nThere have been many attempts to address these issues in the academic nance literature, and these wont be surveyed here.13 Beyond these puzzles there are a set of facts that are still not well explained by any existing model.\nTrading volume is probably the most important.\nFinancial markets generally exhibit large amounts of trading volume, and it is dicult to imagine that this can be driven by any situation not involving continuing disagreement between individuals.\nBeyond the level of volume, there are also some interesting dynamic eects which include persistence and cross correlations with returns and market volatility.14 Also, volume has recently been shown to be a long-memory process with persistence extending out many periods [see, e. g., Logato & Velasco (2000)].\nAt this time no convincing mechanisms exist for any of these features.", "Equally puzzling, but more extensively studied, the persistence of volatility is another major feature that lacks an accepted explanation.\nWhile the direction of stock returns is generally unpredictable, their magnitudes are often very predictable.15 Stock markets repeatedly switch between periods of relative calm and periods of relative turmoil.\nThis feature remains one of the most robust, and curious, in all of nance.\nAlthough much is known about the structure of volatility persistence, little is known about its causes.16 Similar to volume persistence, it is also a potential long-memory process.17 Beyond simple persistence there are some more complicated issues in the dynamics of volume and volatility.18 Closely related to volume and volatility persistence is the issue of fat tails, or excess kurtosis.\nAt frequencies of less than one month the unconditional returns of nancial series are not normally distributed.\nThey usually display a distribution with too many observations near the mean, too few in the mid range, and again, too many in the extreme left and right tails.\nThis feature has puzzled nancial economists since it was discovered by Mandelbrot (1963).\nRecently, it has gained more attention since practical problems of risk management critically depend on tail probabilities.\nPrecisely tuned complex derivative portfolios need very good estimates of potential tail losses.\nReturn distributions eventually get close to normal as the time horizon is increased.\nAt the annual frequency, the normal distribution is not a bad approximation.\nFat tails are not 13Two recent models attempting to address many of these features are Campbell & Cochrane (1999) and Bansal & Yaron (2004).", "14Many of these are documented in Gallant, Rossi & Tauchen (1992) and Gallant, Rossi & Tauchen (1993).", "15This has been well known since Mandelbrot (1963), and has led to a large industry of models for tting and testing volatility dynamics.\nSee Bollerslev, Engle & Nelson (1995) for a survey.", "16One of the few examples of theoretical models generating persistent volatility is McQueen & Vorkink (2004).", "17See Ding, Granger & Engle (1993), Andersen, Bollerslev, Diebold & Labys (2003), and also Baillie, Bollerslev & Mikkelsen (1996).", "18These include connections between volatility and volume to return autocorrelations, LeBaron (1992) and Campbell, Grossman & Wang (1993), and temporal asymmetries in volatility documented in Dacorogna, Gencay, Muller, Olsen & Pictet (2001).\nAlso, there are general indications that volatility tends to lead volume, but not vice versa, Fung & Patterson (1999).", "entirely independent of volatility persistence.\nThe unconditional distributions of most volatility persistent processes are fat tailed, even when their conditional distributions are Gaussian.\nBeyond the frequency of large moves there is a continuing debate about the exact shape of the tails of return distributions.\nIt is possible that these may be described by power laws.19 One of the reasons for this wide range of puzzles is another justication for nance being a good agentbased test bed.\nFinancial data are generally plentiful, accurate, and available on many dierent aspects of nancial market functions.\nGood time series of up to forty years are available on prices and volume.\nSeries of lengths up to one hundred years are available for lower frequencies, and for certain securities.\nOver the past twenty years, extremely high frequency data has become available.\nThese series often record every trade or every order entering a nancial market, and sometimes include some information as to the identity of traders.\nTherefore, researchers have a detailed picture of exactly how the market is unfolding, and the exact dynamics of trade clearing.\nAlso, series are available that show detailed holdings of institutions, such as mutual funds, and that record the ows coming in and out of these funds.\nFor individuals a few series have been used that reveal the trades of investors accounts at various brokerage rms.20 This gives an amazing level of detail about the behavior of individuals which will be useful in the construction and validation of agent-based models.\nFinally, experimental data are available that can be used to line up and calibrate agent behavior.\nSeveral of the models covered here have already done this, and more examples of using experiments are given in Duy (2005).\nFinance experiments are particularly appealing since they often can be done at time scales that are reasonable for the real data.\nIt is more credible that you can simulate a day of trading in the laboratory, than to simulate someones entire life cycle.", "To summarize, nancial markets are particularly well suited for agent-based explorations.\nThey are large well-organized markets for trading securities which can be easily compared.\nCurrently, the established theoretical structure of market eciency and rational expectations is being questioned.\nThere is a long list of empirical features that traditional approaches have not been able to match.\nAgent-based approaches provide an intriguing possibility for solving some of these puzzles.21 Finally, nancial markets are rich in data sets that can be used for testing and calibrating agent-based models.\nHigh quality data are available at many frequencies, and in many dierent forms.", "19Good surveys on power laws in nance are Cont (2001), Dacorogna et al.\n(2001), Mantegna & Stanley (1999), and Lux (2002).\nPower laws are dicult to formally test empirically.\nHowever, Solow, Costello & Ward (2003) is one framework for attempting to build a test of power law behavior.\nLeBaron (2001c) provides an example showing how visual tests of power laws can be deceiving.", "21There are other explanations that may yet prove to be important.\nThese come from the area of behavioral nance which allows for deviations from strict rationality, and emphasizes the presence of certain key psychological biases which have been experimentally documented.\nSee Hirshleifer (2001) and Barberis & Thaler (2002) for recent surveys on this literature.", "The remainder of this chapter will summarize recent work on agent-based computational models in nance.\nThe next section introduces some of the computational tools and design issues that are important in building markets.\nSection 3 covers articial market models that attempt to recreate an entire market.\nSection 4 covers a few other types of markets which do not t into the earlier categories.\nSection 5 covers some on-going debates and criticisms of agent-based markets, and section 6 concludes and suggests questions for the future.", "In constructing an agent-based nancial market the researcher is faced with a large number of basic design questions that must be answered.\nUnfortunately, there is often little guidance on which direction to follow.\nThis section briey overviews most of these questions which will be seen again as the setup of dierent markets is covered in later parts of this survey.", "Probably the most important question is the design of the economic environment itself.\nWhat types of securities will be traded?\nWill there be some kind of fundamental value, and how does this move?\nIs there an attempt to model a large subset of the macro economy or just a very specic nancial market?\nAs in any economic modeling situation these are not easy questions.\nIn the case of agent-based models they are often more complicated, since the accepted knowledge of how to craft good and interesting worlds of heterogeneous agents is still not something economists are very good at.\nIt is not clear that the knowledge base for building representative agent macro economies will necessarily carry over into the agent-based world.\nThis design question is probably the most important, and the most dicult to give guidance on.", "Agent preferences are an important decision that must be made.\nQuestions about preference types are critical.\nShould they be simple mean/variance preferences, or standard constant relative risk aversion form?\nAlso, myopic versus intertemporal preferences is another issue.\nThe latter brings in more realism at a cost of additional complexity in the learning process.\nIt is also possible that certain behavioral features, such as loss aversion, should be included.\nFinally, there may be an argument in certain cases to avoid preferences altogether, and to concentrate simply on the evolution of specic behavioral rules.\nThe use of well-dened preferences is the most comfortable for most economists.\nTheir use facilitates comparisons with other standard models, and they allow for some welfare comparisons in dierent situations.\nMost applications to date have stayed with myopic preferences since the added complexity of moving to an intertemporal framework is signicant.\nIt involves learning dynamic policy functions in a world which already may be ill-dened.", "Many models considered here focus on the fundamental problem of price formation, and the method for determining prices is critical.\nAs we will see, many methods are used, but most fall into one of four categories.\nThe rst mechanism uses a slow price adjustment process where the market is never really in equilibrium.\nAn early example of this is Day & Huang (1990).\nIn this case a market-maker announces a price, and agents submit demands to buy and sell at this price.\nThe orders are then summed; if there is an excess demand the price is increased, and if there is an excess supply the price is decreased.\nThe price is often changed as a xed proportion of the excess demand as in equation (1).", "An advantage and disadvantage of this is that the market is never in equilibrium.\nThis might be reasonable for the adaptively evolving situations that are being considered.\nHowever, it also may be a problem, since, depending on , these markets may spend a lot of time far from prices that are close to clearing the market.\nAnother issue is how is excess demand handled?\nAre excess demanders supplied from some inventory, or is rationing used?\nA second market mechanism is to clear the market in each period either numerically, or through some theoretical simplications that allow for an easy analytic solution to the temporary market clearing price.\nTwo examples of this method are Brock & Hommes (1998) and Arthur, Holland, LeBaron, Palmer & Tayler (1997).\nThis method reverses the costs and benets of the previous method.\nThe benet is that the prices are clearing markets, and there is no issue of rationing, or market-maker inventories that need to be dealt with.\nThere are two critical problems for this type of market.\nIt may impose too much market clearing, and it may not well represent the continuous trading situation of a nancial market.\nAlso, it is often more dicult to implement.\nIt either involves a computationally costly procedure of numerically clearing the market, or a simplication of the demands of agents to yield an analytically tractable price.22 22A close relation to this method is to assume that prices are a function of the aggregation of expectations as in Kirman (1991) and De Grauwe, Dewachter & Embrechts (1993).\nAlthough trades dont actually take place, these papers do provide a clean mechanism for determining the current period price, and they can concentrate on agent expectation formation.", "These two pricing mechanisms take opposite extremes in terms of market clearing.\nTwo other mechanisms fall somewhere in between.\nThe most realistic mechanism from a market microstructure perspective is to actually simulate a true order book where agents post oers to buy and sell stock.\nOrders are then crossed using some well-dened procedure.\nExamples of this are Chiarella & Iori (2002) and Farmer, Patelli & Zovko (2005).\nThis method is very realistic and allows detailed analysis of trading mechanisms.\nIts only drawback is that these same institutional details need to be built into both the market architecture, and the learning specications of agents.\nAny market that hopes to simulate realistic market microstructure behavior should follow this procedure.", "The nal market mechanism that can be used is to assume that agents bump into each other randomly and trade if it benets them.\nThis is closest to a random eld sort of approach as in Albin & Foley (1992).\nA nance example of this is Beltratti & Margarita (1992).\nThis mechanism may have some connections to oor trading as used in the Chicago futures and options exchanges.\nIt might also be a good representation for informal markets such as foreign exchange trading where, until recently, a lot of trade was conducted over the telephone.\nIt would appear realistic for situations where no formal trading markets have been established.\nHowever, it may not be very natural in places where trading institutions are well dened, and function to help buyers meet sellers in a less-than-random fashion.", "Much of the agent-based literature has used tools taken from the articial intelligence literature to model learning.\nOne of these is the Genetic Algorithm (or GA), which is a key component in many, but not all, agent-based nancial markets.23 It is viewed by some as a power tool for modeling learning and adaptation.\nIt is an alternative to more traditional learning approaches such as Bayesian learning and adaptive linear models.\nIt is also controversial in that it is not clear that this is a good mechanism for replicating the learning process that goes on inside market participants heads.", "The most common application of the GA is as a simple optimization technique used in various problem solving situations.\nIt is one of several optimization tools that are useful in situations where traditional hill climbing methods can fail, such as multi-peaked objectives, or nondierentiable objective functions, possibly with discrete input variables.\nAlthough in this context the behavior of the GA is still not completely understood, this is a far simpler setting than the multi-agent models that will be considered in this survey.", "23More information on genetic algorithms along with many other learning algorithms is presented in Brenner (2005) and Duy (2005).", "Many beginning researchers view the GA as a kind of black box, and simply follow previous work in setup and structure.24 This approach is probably a mistake.\nIt is important to think more about evolutionary computation in general than about the particular pieces of the GA. The general eld of evolutionary computation includes other methods such as evolutionary programming, and evolutionary strategies, and genetic programming.\nFor the consumer of these techniques distinctions are somewhat unnecessary, and parts of dierent methods should be used when the problem warrants it.25 Setting up an evolutionary learning framework requires several preliminary steps.\nFirst, the mapping from behavioral rules into a genetic structure is important.\nIn some contexts this might involve simply combining real-valued parameters into a vector of parameters, or in some instances it might involve coding real values as strings of zeros and ones.\nIt also may involve taking a complex representation such as a neural network and mapping it into some simpler object.\nOne needs to end up with some type of object that represents the behavior and that can be easily manipulated by evolutionary operators.", "In most evolutionary methods there will be a population of the previously mentioned solutions.\nIn the individual optimization setting the information contained in the population is crucial to aiding in the search for solutions.\nAttached to each solution or rule is a tness value.\nThis is essentially the objective function for this potential solution.\nIn the traditional optimization setting this isnt a problem since it is most likely a well-dened function of the given parameters.\nThis gets more dicult in mutli-agent settings where the question of optimality may be less well dened.\nGiven a tness value, the population can now be ranked.\nThe computer simulates evolution by removing some set of low tness solutions.\nThe fraction of the population removed is an important design parameter to be decided.\nSetting this too high may cause the population to converge too quickly to a suboptimal solution.\nSetting it too low may make selection weak, and the GA may converge far too slowly.", "In nancial settings agents and strategies can be evolved using either wealth, or utility-based tness.\nIn the case of wealth, evolution of the agents themselves might be unnecessary since agents gaining more wealth will have a larger impact on prices.\nUtility is another possible tness measure.\nAgents can be evaluated based on ex post utility achieved.\nRules or trading strategies are often evolved and evaluated.\nThe simplest criterion is to use a forecast-based measure such as mean squared error, or mean absolute error, and to promote rules that minimize this.\nForecasts are then converted into asset demands using preferences.\nThis is a very transparent route, and it is possible to evaluate and compare agents based on their forecasting 24Goldberg (1989) is the classic book for early GA adopters.", "performance.\nThis also aligns with the bulk of the learning literature in macroeconomics, which often concentrates on forecast evaluation.", "A second route is to ignore forecasts altogether and to deal directly with asset demands and strategies.\nThe strategies are then evolved based on their impact on agents utilities.\nThis may be more dicult than considering forecast errors, but it eliminates an extra step in converting forecasts to demands and is a little cleaner from a decision-theoretic standpoint.\nIn some cases this also avoids the need to estimate variances and other higher moments since risk would be taken into account.\nFinally, it is important to remember that all these tness measures will most likely be measured with noise.\nFurthermore, it is not clear that the time series used to estimate them are stationary.\nAgents may end up choosing dierent lengths of history, or memory, in their rule evaluations, which can translate into interesting dynamics.\nIn a nonstationary world, there is no a priori argument for any particular history length.\nThis greatly complicates the evolutionary process, and distances these problems from those often considered in the evolutionary computation literature.", "One of the biggest problems in market design is how information is presented to the agents, and how they process it.\nTheoretically, this is the daunting task of converting large amounts of time series information from several series into a concise plan for trading.\nTo handle this researchers are often forced to predene a set of information variables as well as the functional structure used to convert these into trading strategies.\nA second problem is how information is revealed about securities.\nAre there special signals visible only to certain agents?\nAre there costly information variables?\nHow frequent are information releases?\nUnfortunately, there are no easy answers to these questions.", "This is another area where technology is often taken from the articial intelligence literature.\nIn Arthur et al.\n(1997) a method known as a classier system is used, which will be described later in this chapter and in Brenner (2005) and Duy (2005).\nIn Beltratti & Margarita (1992) and LeBaron (2001b) neural networks are used to represent trading strategies.\nHowever, strategies can be as simple as a vector of parameters as in Lettau (1997).", "How agents learn from each other is another important design question.\nThis is often known as social learning, and has been the subject of much discussion in the agent-based modeling community.26 At one 26See Vriend (2000) for a description and examples.", "extreme, agents may operate completely on their own, learning rules over time, and only reacting with others through common price and information variables.\nHowever, in nancial settings it may be useful to try to implement some form of communication across agents, or even to transfer rule-based information across individuals from generation to generation.\nHow this information transfer is handled may be critical in market dynamics; these information correlations cause eventual strategy correlations, which can translate into large price movements and other features suggestive of a breakdown in the law of large numbers.", "The nal design issue is the creation of useful benchmark comparisons.\nIt is very important to have a set of parameters for which the dynamics of the market is well understood.\nThis demonstrates certain features in terms of learning dynamics and trading.\nAn important benchmark might be the convergence to a well dened rational expectations equilibrium for certain parameters.\nThe existence of such a benchmark further strengthens the believability of a computational market.\nParameter sensitivities can reveal critical factors in a simulation that lead a market towards or away from an equilibrium.\nFinally, the dynamics of the learning process may be just as interesting in a neighborhood of an equilibrium as far away from an equilibrium.\nTo make this distinction the denition of a benchmark is essential.", "It is easy to get lost in the many dierent types of models used in agent-based nancial markets.\nSeveral approaches are used, and it is often dicult to distinguish one model from the next.\nThis survey will take an initial stand on trying to categorize the many models that exist in a hope that this will help new researchers to better sort out what is going in the eld.\nAt such an early stage, it is still possible that some may argue about how markets are being categorized, or that some markets belong in multiple categories, or that the categories themselves are wrong.\nMost of the earliest models were intended to create an entire functioning nancial market.\nThey were often referred to as articial nancial markets.\nThe next several subsections deal with dierent parts of this literature.", "Most of the earliest articial nancial markets carefully analyze a small number of strategies that are used by agents to trade a risky asset.\nThe advantage of a small set of strategies comes in tractability, and in many cases these models are more analytic than computational.\nMany of these models follow the early lead of Frankel & Froot (1988), Kirman (1991), and De Grauwe et al.\n(1993).\nIn these papers it is assumed that there is a population of traders following two dierent types of strategies, labeled technical and fundamental.\nTechnical traders are generally responsive to past moves in prices, while fundamental traders make decisions based on some perceived fundamental value.\nThe relative numbers in the populations usually respond to past performance of the given strategies.\nThe simplicity of these models makes them an important base case for the more complicated computational models which will be discussed later.\nMost of these models are analytic, but several with small strategy sets still require computational techniques to get their dynamics.\nThese will be discussed here.27 One of the earliest few-type nancial market models was developed by Figlewski (1978).\nThis market model examines the impact of shifting wealth across dierentially-informed agents in a simple asset pricing framework.\nIn this market agents possess a critical piece of information which might be unrealistic when considering real nancial markets.\nIt is assumed that they know the wealth level of the other type of agent in the market.\nThis is critical in forming price expectations across the two types.\nThere is an ecient market benchmark, and many of the simulation runs converge to this.\nCertain sets of parameters do not perform well in terms of convergence.\nAmong these is the case where one set of agents has better information in terms of signal variance.\nIn this case the simulated variance in the market is 14 percent larger than they ecient market benchmark.\nActually, the simulations show that overall market eciency might be reduced by the addition of traders with inferior information.\nThough this paper contains little information on the dynamics of prices and trades, it is still an important early reminder on how wealth dynamics aect the convergence to an ecient market.", "Kim & Markowitz (1989) are interested in the problem of market instability, and the impact that computerized strategies such as portfolio insurance may have had on the crash of 1987.\nPortfolio insurance strategies attempt to put a oor on the value of a portfolio through the use of a dynamic trading strategy.\nAs the market falls, investors move holdings to cash to stop their losses.\nIt is obvious that a market with many traders using portfolio insurance strategies can be very unstable.\nSince the strategy is well dened, this allows for a simple computational test bed to assess their impact.\nThe authors nd that price volatility, trading volume, and the size of extreme price changes is increased as the fraction of portfolio insurance traders increases.", "27Other important early papers in this area which are discussed in Hommes (2005) are Beja & Goldman (1980), Brock & Hommes (1998), Chiarella (1992), Cont & Bouchaud (2000), Day & Huang (1990), Lux (1997), and Zeeman (1974).", "The papers described in this section are more computational than those mentioned previously.\nIn most cases the small sets of tractable trading rules are replaced with larger sets of strategies, which are usually represented using various computational techniques.\nThese will be referred to as many-type models.\nThis rst section concentrates on applications where the economic environment is well understood and where there is often a simple homogeneous rational expectations equilibrium which gives a useful benchmark comparison.\nLettau (1997) provides a good example of a computational model of this type.\nHe implements a nancial market model with a set of heterogeneous learning agents, that is simple, transparent, and easy to implement.\nThe model is a portfolio choice environment where investors must decide what fraction of wealth to put in a risky asset.\nThere is also a risk-free asset paying zero interest.\nThe world is a repeated two-period model with myopic preferences based only on wealth in the second period.\nThe risky asset has an exogenously given price and pays a random dividend, d, which follows a normal distribution.\nThe second period wealth of agents is given by,", "This is clearly a very simplied market.\nNo attempt is made to look at the feedback from agents demands to returns on the risky asset.\nThere is no consumption, and wealth is not linked to agents impact on asset prices, or evolution.\nHowever, it is a very straightforward test of learning in a nancial market.", "Given the normally distributed dividend process, there is a well-known optimal solution to the portfolio problem given by, s = (d p) (4) where 2 d is the variance of the random dividend payout.\nThe main exercise in Lettaus paper is to see if and when agents are able to learn this optimal portfolio strategy using a genetic algorithm.\nIn general, agents policy functions could take the form of", "but Lettau simplies this by using the optimal linear functional form for agent i, This gives the agents a head start on the portfolio problem, but they still need to learn the optimal .28 The market is run for S periods with new independent draws of the dividend for each period.\nEach agent continues to use the portfolio determined by i, which remains xed.\nAt the end of each block of S the genetic algorithm (GA) is run, and the set of agent parameters is redrawn.\nAgents are parameterized with a bitstring encoding given by", "L j=1 j,i2j1 where j,i is the bitstring for the strategy of agent i. The GA rst gets a tness value for each agent estimated over the S periods using\nVi = S s=1 U(wi,s).\n(9)", "This sets the tness to the ex post estimated expected utility over the sample.\nA new population is chosen using a technique known as tness proportional selection.\nEach agent is assigned a probability using pi = 1/ViJ j=1(1/Vj).\n(10)", "Then a new population of length J is drawn from the old, with probability pi assigned to each type.\nThis new population is now the basis for the crossover and mutation operators in the GA. Each new rule is crossed with another rule chosen at random according to a xed crossover probability.\nCrossover chooses a midpoint in each of the two bitstrings, and then combines the rst substring of one rule, with the second substring of another rule.\nThis new set of rules is then mutated, where each bit is ipped according to a xed probability.\nIn Lettaus framework the mutation rate is slowly decayed over time, so that eventually mutation probabilities go to zero.\nThis is a form of cooling down the learning rates as time progresses.\nAfter mutation, the new population is ready to go back to purchasing the risky asset for another S periods before the GA is run again.", "Lettaus results show that in various specications the GA can learn the optimal parameter for the 28A more complicated functional form is tried, but the only change is that convergence is slowed down by the need to learn more parameters.", "portfolio policy, nevertheless, there are some important caveats.\nFirst, the specication of S is crucial.\nFor example, Lettau ran experiments for which the optimal value of  was  = 1.0.\nWith S = 150, he found that the experimentally-determined value of alpha in his agent population was 1.023.\nHowever, for S = 25 this average population alpha increased to 1.12, substantially dierent from the optimal value.\nIt is not surprising that sample size matters, but this is a fact that can often be forgotten in more complicated setups where this choice is not as transparent.\nAlso, Lettaus estimated  values are all biased above the optimal value.\nThe intuition for this is clear for the case where S = 1. Ex post it is optimal for S to be 0 or 1 depending only on the draw of d. Lettau sets the mean, d, to a positive value, so that, on average, it will be better to hold the risky asset.\nThis leads to an upward bias for the smaller values of S. In larger samples this bias dissipates as agents are better able to learn about the advantages of the diversied optimal strategy.\nThis small bias is an important reminder that learning diversied strategies can be dicult.", "This is a very stylized and simplied agent-based market.\nThere is no attempt to model the price formation process at all.\nTherefore, this cannot be viewed as an attempt to model an actual nancial market, in which the dependence between todays price and traders strategies is the most critical aspect of the agent-based modeling approach.\nHowever, it is a very clean and straightforward setup and hence a good learning tool.\nAlso, the biases and sample size issues that it brings up will also pertain to many of the much more complicated models that will be considered later.29 In Arifovic (1996) a much richer more extensive model is constructed.\nOnce again, the model stays close to a well-dened theoretical framework while extending the framework to include learning agents.\nThe model that is used is the foreign exchange model of Kareken & Wallace (1981).\nThis is a two-country, two-period, overlapping generations model.\nAgents have income and consumption in both periods of their lives.\nAgents only means for saving income from the rst to the second period of their lives is through either countrys currency.", "Agents maximize a two-period log utility function subject to their budget constraints as in, max ct,t,ct,t+1 log ct,t + log ct,t+1 st. ct,t  w1  m1,t p1,t  m2,t p2,t ct,t+1  w2 + m1,t p1,t+1 + m2,t p2,t+1.", "m1,t and m2,t denote the money holdings of agents in the two currencies.\nThere is only one consumption 29Another simple example of this can be found in Benink & Bossaerts (2001).", "Given this setup, all agents care about in terms of money holdings are the relative returns of the two currencies.\nIn an equilibrium where both currencies are held, these returns must be equal.", "It is also easy to show that the agents maximization problem yields the following demand for savings: st = m1,t p1,t + m2,t p2,t =\n1\n2 (w1  w2 1", "The model has a fundamental indeterminacy in that, if there exists one price series and an exchange rate paring that constitutes an equilibrium, then there will exist innitely many such equilibria.\nOne of the interesting issues that Arifovic is exploring is whether the GA learning mechanism will converge to a single exchange rate.\nSargent (1993) explored this same question; he found that certain learning algorithms converge, but the nal exchange rate depends on the starting value.", "The multi-agent model is set up with a population of agents in each generation.\nAgents are represented with a bitstring which represents both their rst period consumption decision, and the fraction of their savings to put into currency 1.\nA bitstring of length 30 is divided as 20 binary bits for consumption in period 1, and 10 for the fraction of savings put into currency 1.\nThese two values completely determine a period 1 agents behavior through life.\nThe price level in this model is determined endogenously.\nThe agent bitstings determine their desired real savings in each currency, which gives the aggregate demand for real balances in the two currencies.\nNominal currency supplies are given, so this determines the price level in each currency.\nThis setup avoids some of the complexities that appear in other papers in nding prices.", "The evolution of strategies is similar to Lettau (1997).\nThe tness of a strategy is determined by its ex post utility, and a new population is drawn using tness proportional selection.\nAgents are paired, and a crossover operator is applied to each pair with a given probability generating two new children.\nWhen crossover is not used, the children are direct copies of the parents.\nThese children are then mutated by ipping bits with a certain probability.\nThe tness of the new rules is then estimated by implementing them on the previous round of prices and returns.\nAt this point all four of the children and parents are grouped together, and the ttest two of this set are put into the next generations population.\nThis is known as the election operator, which was rst used in Arifovic (1994).\nIt is designed to make sure that evolution continues to progress to higher tness levels.", "Arifovic analyzes the dynamics of this market for various parameter values.\nThe results show that the rst-period consumption level converges to a stable value close to the optimum.\nHowever, the exchange rate continues to move over time, never settling to any constant value.\nThere is an interesting interpretation for this dynamic price process.\nIn the equilibrium the return on the two assets is the same, so the learning agents are indierent between holding the two currencies.\nGroups of agents move to holding one currency or another, the exchange rate moves around as they shift demands between currencies.\nIn a model such as this, it is clear that a constant exchange rate equilibrium can only be maintained through some mechanism that shuts down learning and exploration in the model.\nArifovic also shows that similar features are obtained in experimental markets.30 Routledge (2001) also critically examines what happens when leaning agents are introduced into a wellknown model.\nHe implements GA learning in a version of the heterogeneous information model of Grossman & Stiglitz (1980).\nThis is a repeated version of a model where agents can purchase a costly signal about a future dividend payout of a stock.\nLearning takes place as agents try to convert the noisy signal into a forecast of future dividends.\nAgents who decide not to purchase the signal must use the current price to infer the future dividend payout.\nIndividual agent representations encode not just the decision on whether to purchase the signal but also the linear forecast parameters which convert the signal into a conditional expectation of the future dividend payout.", "Grossman & Stiglitz (1980) show that there is an equilibrium in which a certain fraction of agents will purchase the signal.\nRoutledge (2001) shows that this can be supported in the GA learning environment.\nHowever, there are also sets of parameters for which the original equilibrium proves to be unstable.\nThe dynamics of this instability are very interesting.\nThere is instability and exploration going on around the equilibrium, and by chance a few more-informed agents may enter the market.\nThe change in market proportions of informed versus uninformed agents means that the current linear forecast parameters are now wrong.\nIn particular, the uninformed need to learn how to interpret the price with fewer of their type around.\nUnfortunately, as the number of uniformed agents falls, the ability of their population to learn decreases due to small sample size.\nTypically the end result is convergence to a situation in which all agents", "The next set of articial market models moves farther from testing specic models and more towards understanding which types of strategies will appear in a dynamic trading environment.\nAll have at their core a philosophy of building a kind of dynamic ecology of trading strategies and of examining their coevolution over time.\nThis methodology attempts to determine which strategies will survive, and which will fail.\nAlso, one observes which strategies will emerge from a random soup of starting strategies, and which are capable of self-reinforcing themselves, so that survival is possible.\nThey also attempt to perform a very direct exploration into the dynamics of market eciency.\nIf the market moves into a state where certain ineciencies appear, then the hope is that the evolutionary process will nd new strategies to capitalize on this.\nThe objective is to explore a market that may not be ecient in the textbook sense, but is struggling toward informational eciency.", "The Santa Fe Articial Stock Market, SF-ASM, is one of the earliest in this set of models.\nIt is described in Arthur et al.\n(1997), and also in LeBaron, Arthur & Palmer (1999).32 The basic objective of the SF-ASM is to understand the behavior of an environment of evolving trader behavior, where prediction strategies compete against each other.\nPart of this objective is to nd if and when the market converges to a tractable rational expectations equilibrium.\nA second part is to explore the dynamics of the computational model for the cases in which convergence does not occur, and to compare these to results from real nancial time series.", "The basic economic structure of the market draws heavily on existing market setups such as Bray (1982) and Grossman & Stiglitz (1980).\nThe traders have one-period myopic preferences of future wealth with constant absolute risk aversion (CARA) utility functions.\nThere are two assets that agents trade in the market, a risky stock paying a random dividend, dt, and a risk-free bond paying a constant interest rate, r. The dividend follows an autoregressive process as in, dt = d + (dt1  d) + t, (14)", "where t is gaussian, independent, and identically distributed, and  = 0.95 for all experiments.\nIt is well 31Routledge (1999) presents similar results in an analytic framework.", "32There is also an earlier version of the SFI market which is described in Palmer, Arthur, Holland, LeBaron & Tayler (1994).\nThis market has one crucial dierence with the later market in that it implements an excess demand price adjustment mechanism.\nThe later version uses a form of market clearing.", "known that, assuming CARA utility functions, and Gaussian distributions for dividends and prices, the demand for holding shares of the risky asset by agent i is given by, where pt is the price of the risky asset at t, 2 t,i,p+d is the conditional variance of p\n+\nd at time t for agent i,  is the coecient of absolute risk aversion, and Et,i is the expectation for agent i at time t. Assuming a xed number of agents, N, and a number of shares equal to the number of agents gives, which closes the model.\nThe SF-ASM includes an important benchmark for comparison.\nThere exists a linear homogeneous rational expectations equilibrium in which all traders agree on the model for forecasting prices and dividends.\nIn the equilibrium it is easy to show that the price is a linear function of the dividend, where dt is the only state variable.\nThe parameters a and b can be easily derived from the underlying parameters of the model by simply substituting the pricing function back into the demand function and setting it equal to 1, which is the equilibrium holding of shares for each agent.", "The most important part of the SF-ASM is its implementation of learning and forecasting.\nThis is done with a classier forecasting system, which is a modication of Hollands condition-action classier[Holland (1975), Holland, Holyoak, Nisbett & Thagard (1986)].\nIt maps current state information into a conditional forecast of future prices and dividends.33 Traders build their own individual forecasts of future prices and dividends by matching specic forecasting rules to current market conditions.\nIn the classier system traders can use, or ignore, any part of a predened set of current information in their forecasts.\nIn the SF-ASM classiers are used to select between dierent forecasts that are conditioned on certain pieces of market information.\nInformation is coded into bitstrings, and each bit is connected to dierent ranges for various indicators.\nThe information bits are classied either as fundamental or technical.\nFundamental bits refer 33Classiers are not used extensively in economic modeling.\nExamples of other studies using classiers are Marimon, McGrattan & Sargent (1990) and Lettau & Uhlig (1999).\nSee Brenner (2005) and Duy (2005) for more discussion.", "to the current price relative to the current dividend level.\nTechnical bits are trend following indicators that refer to the current price relative to a moving average of past prices.34 A classier forecasting rule is matched to a specied vector of these conditions, and corresponds to a linear price-dividend forecast of the form", "The classier selects the appropriate real-valued pair, (aj, bj).\nTherefore, the classier selects a piecewise linear forecasting rule which is then used in the demand relationship (15).\nIt is important to note that given the linear structure of the forecasting rule and the rational expectations equilibrium in (17), neither fundamental nor technical bits would provide additional information if the market were in the equilibrium.", "At the end of each period, each trader with probability p engages in a learning process to update his current set of forecasting rules for the next period and with probability (1  p) leaves his current set of forecasting rules unchanged.\nThe probability, p, is an important model parameter that determines the average number of periods between learning for each trader as a function K = K(p).\nThis K is referred to as the learning rate.\nLearning takes place with a modied genetic algorithm (GA) designed to handle both the real and binary components of the rule sets.\nThe worst performing 15 percent of the rules are dropped out of an agents rule set, and are replaced by new rules.\nNew rules are generated using a genetic algorithm with uniform crossover and mutation.\nFor the bitstring part of the rules, crossover chooses two t rules as parents, and takes bits from each parents rule string at random.35 Mutation involves changing the individual bits at random.\nCrossover also is implemented on the real components of the forecasting rules too.\nThis is one of the earlier applications of a real-valued crossover operator in nance.", "One of the objectives of the SF-ASM was to examine the dynamics of learning, and to explore its likelihood of convergence to an ecient market equilibrium.\nExperiments are performed for two values of the learning rate.\nA slow-learning experiment sets the average time between runs of the GA to K = 1000, and a fastlearning experiment sets the average time between runs to K = 250.\nIn the rst case, the market converges to the benchmark rational expectations equilibrium, where all agents agree on how to process the fundamental dividend information.\nThey also ignore all other information.\nIn the fast-learning experiments, K = 250, a very dierent outcome occurs.\nThe market does not appear to converge, and it shows several indications of 34The bits code these based on conditions.\nAn individual bit would refer to the test pt/mat > 1.\nIf this is true the bit is set to 1, and if it is false it is set to 0.\n35Selection is by tournament selection.\nThis means that, for every rule that is needed, two are picked at random and the strongest is taken.", "interesting features in the stock return time series.36 Among these are nonnormal return distributions, or fat tails, persistent volatility, and larger amounts of trading volume than for the slow learning case.\nAll of these are elements of the empirical puzzles mentioned in the early sections of this chapter.\nThough the SF-ASM does a good job in replicating these facts qualitatively, no attempt is made to quantitatively line them up with actual nancial data.\nIndeed, the SF-ASM never even clearly states what it considers to be the frequency of the returns series that it generates, or whether the underlying dividend process is realistic.\nThe SF-ASM is has formed a platform for other explorations.\nJoshi, Parker & Bedau (2000) explore the interactions between the technical and fudamental traders.\nThey nd that the use of technical trading bits is a dominant strategy in the market.\nIf all other traders are using technical bits, then it would be in the interest of new agents to use them too.\nAlso, if all other agents are using fundamental bits only, then it is optimal for the new agent to add technical bits as well.\nThis strongly suggests that trend-following behavior may be dicult to remove from a market.\nThe most sophisticated addition to the SFI classiers is in Tay & Linn (2001), who replace the classiers with a fuzzy logic system.", "The SF-ASM market has generated much interest since its software is now publicly available.\nIt was originally written in the programming language C, then objective-C, and nally ported to the Swarm system.\nJohnson (2002) gives an overview and critique of the software from a design perspective, and Badegruber (2003) provides an extensive replication and reliability study.\nIt is fair to summarize that the software is not easy to read or use.\nMuch of this stems from its long history on several dierent platforms.\nAlso, it began before objective languages were popular, and was only adapted to objective form in its later versions.\nIt was not built to be an objective piece of code from the start.", "Another important software replication issue arising from work with the SF-ASM is presented in Polhill, Izquierdo & Gotts (2005).\nThese authors show that the precise trajectory dynamics in the SF-ASM can be altered by making mathematically irrelevant changes in the code.\nFor example one might change, d\n=\na + b c (19)", "Although these two equations are the same, they generate dierent code in the compiler.\nThis change appears 36This parameter sensitivity is closely related to the changes observed in Brock & Hommes (1998) as the intensity of choice parameter is changed.", "to have no impact on the general results, but it does impact the exact replication of trajectories.\nRuns using the two dierent forms will eventually diverge.\nThis is an interesting reminder about the importance of nonlinearities inside these large systems, and on the diculties in replicating exact trajectories across dierent computing platforms.\nWhile general statistical properties and features should be maintained, exact replications may be an elusive goal.", "In addition to software critiques of the SF-ASM, there are also important design issues to consider.\nMany of these are covered in LeBaron (forthcoming 2005).\nQualitatively, the classier system has proved to be a very complicated and unwieldy way to model and understand the market dynamics.\nMany parameters are needed to dene the operation of the classier, and it not clear which of these is important.\nAlso, the implementation of the classier is often criticized.\nEhrentreich (forthcoming 2005) addresses the GA and its impact on the classier bitstrings.\nHis claim is that the original SF-ASM GA mutation operator was biased, and he implements a new operator that he claims is unbiased.\nIn his modied market bitstrings contains fewer 1s and 0s which connect forecasts to information bits.\nAlso, the emergence of technical trading rules does not occur.\nThis is an interesting modication, but the entire classier system makes it dicult to judge what is unbiased in terms of mutation.\nThere is a generalizer system which periodically removes bits in the classier from rules that havent been used recently.\nThis puts a downward pressure on bit-setting in the Ehrentreich (forthcoming 2005) system.\nSecond, it is not clear whether one has to have an unbiased mutation operator in terms of bitstrings.\nOne could view a biased operator as putting many possible conditional rules out in public view, and then it is the agents choice to ignore them.\nThe traders are designed to ignore useless rules since the forecast performance of these rules will be inferior to the others.\nDisagreements about the right mechanism here indicate why the classier system is a dicult to implement and completely understand.\nOne major question about the classifer that is left unanswered is how important the denition of the bitstring is to the dynamics of the market.\nThese bit information values are obviously pre-loaded.\nFinally, another important critique is that by assuming CARA utility functions, the SF-ASM ignores the wealth dynamics of agents.\nIn other words, it is not the case that wealthier agents have a greater impact on prices in the SF-ASM.", "If the general goal of the nancial markets in this section is to see strategies form out of a general set of functional building blocks with little structure entered initially by the designer, then the model of Chen & Yeh (2001) is probably the best model directly addressing this problem.\nThese authors use a computational methodology known as genetic programming to model agent learning.\nThe authors allow the traders to evolve actual predictor functions for nancial forecasting.37 The economic setup in Chen & Yeh (2001) is similar to the SF-ASM except that the price adjustment occurs in response to excess demands as in Palmer et al.\n(1994).\nAlso, demands are based on the forecast of future prices and dividends.\nThis is where genetic programming learning is implemented.\nThe forecast takes the form of Ei,t(pt+1 + dt+1) = (pt + dt)(1 + 1 tanh(2fi,t)), (21) where fi,t is evolved using genetic programming.\nIt takes as inputs ptj + dtj for j = 1, 2,, 10.\nA second important innovation is the use of a common pool of rules, which the authors refer to as a business school.\nThis allows for some strategy learning to occur across agents in a very natural way.38 The rules in the common pool are evolved according to forecast accuracy.\nTraders then decide to update their own strategies based on current performance.\nThey draw rules from the common pool, comparing their performance with their current rules.\nIf the new rule is better they switch, but if they are unsuccessful after several tries, they quit and stay with their current rule.", "Simulations of this nancial market display some features of actual return time series.\nThey exhibit fat tails, and visually they do not settle down to any price level.\nHowever, there are several features that disagree with the actual data.\nFor example, there is a large level of positive skew.\nAlso, the linearly ltered return series are independent, which indicates there may be no persistent eects in volatility.\nAnother interesting feature that the authors test for is a unit root in the price series.\nThe standard tests cannot reject a unit root.\nThis is a little curious since the dividend process is stationary.\nIt is probably sensible that in the long run prices should not diverge too far from the fundamental, and should therefore also be stationary.", "Another nancial market model is the Genoa articial market, Raberto, Cincotti, Focardi & Marchesi (2001).\nIn the original version of their market model the authors used random-order selection, meaning that buy and sell limit orders are generated at random by traders.\nTraders rst determine whether they are a buyer or seller at random, and then place a limit buy or sell order determined by their budget constraints.\nThese limit prices in each case are generated as random variables.\nIn contrast to the previous markets, these traders are generally fairly unsophisticated.\nAs in the study by Cont & Bouchaud (2000) they exhibit a kind of herding behavior.\nBuyers and sellers group into larger dependent sets, which then move together.", "The Genoa articial stock market has an interesting market-clearing property.\nThe limit orders are all 37Genetic programing is discussed in Brenner (2005) and Duy (2005).\nThere have been some implementations of this technology on actual data as in Neely, Weller & Dittmar (1997) and Allen & Karjalainen (1998).\nThe origins of genetic programming go back to Koza (1992).", "collected after a short period has gone by, and then the market is cleared by crossing the supply and demand curves given by the current limit orders.\nThe market-clearing price is then used to clear all of the trades that can be executed on the limit order book.\nThis interesting batch-order book market is very simple and direct.\nSimilar to the other models discussed earlier, the Genoa market generates uncorrelated returns, fat tailed return distributions, and persistent price volatility.", "The nancial market model presented in Beltratti & Margarita (1992) and in Beltratti, Margarita & Terna (1996) is quite dierent from the other markets described here.\nIt is again searching for an emergent pattern in the trading behavior of adaptive agents.\nHowever, unlike the previous models, this one has no organized central trading institution.\nAgents trade in a completely disaggregated fashion in a market where they randomly bump into potential trading partners.\nThis is similar to structures such as Albin & Foley (1992).", "The traders build a forecast of what they think the stock is worth using past information and an articial neural network.\nThe network builds a forecast of the following form, Ei,t(p +\nt\n+ 1) = f(pi,j,t1,pi,j,t1, t1,t1), (22)", "where t1 is the average transaction price at time t 1 across all traders, pi,j,t1 is the last price execution that the trader received, and x refers to the one-period change in x. This is an interesting function because it implies the traders are using both local and global information.\nWhen two traders meet, they compare their price forecasts.\nThe trader with the larger forecasted price then purchases 1 share from the trader with the smaller forecasted price.\nThe trade is executed at the simple average of the two prices.\nThe market keeps track of the average execution price across the random pairings, and this is included in the information sets of the traders.\nAfter a day of trading, traders are allowed to update the weights of their neural networks in a direction that they perceive will improve forecast accuracy.", "Beltratti et al.\n(1996) present many experiments with this basic structure.\nOne of the more interesting explorations tackles the problem of heterogeneous agents with diering levels of complexity.\nThis is covered in Beltratti & Margarita (1992).\nThe population consists of dierent neural network structures.\nTrader sophistication is represented by more complicated neural networks.\nThe more complicated structure comes at a given higher complexity cost, c, that is paid directly by the traders.\nThe simulations show the eventual heterogeneous population depends critically on the value of c. For low levels of c, traders purchase the extra network complexity, and for high levels of c, they eventually only use the simple networks.\nThere is an interesting mid- of c values where both types of strategies are able to coexist.", "In all of the papers reviewed so far, the traders are assumed to behave competitively.\nThat is, they view themselves as having no price impact, and they believe there is little information to be gained by observing other individuals trades.\nChakrabarti & Roll (1999) is an interesting exception to this.\nThese authors model an information acquisition process where agents observe other large traders in the market and adjust their own beliefs based on the observed actions of others.\nThis is in the spirit of other sequential trading models such as Welch (1992).", "The individual traders receive a signal each period, and they also observe the trades of others.\nTheir own trading strategies are based on optimally forecasting the nal payment of the security using Bayesian updating from their initial priors.\nThough the individual strategies are analytically dened, the nal dynamics of the market as a whole requires a computational experiment.\nThe authors employ a novel approach to explore the impact of many dierent parameters.\nThey run many simulations at randomly chosen parameter values, and record various results.\nTo analyze all this data, they run multiple linear regressions on the parameter values, to observe their impact on empirical market outcomes.\nThis may seem like a lengthy and indirect method to understand parameter sensitivity, but it may be important when there are many parameters, and when the interactions between parameters are not well understood.", "The authors analyze many properties of the market, including price volatility, and price prediction error (or tracking).\nAn interesting result is that, when signal diversity increases, price volatility increases, but the price is also a better forecast of future value.\nThis implies that increased trading activity can lead both to greater price movements and to better learning and information-sharing through price signals.\nThis should remind policy makers that simple measures of volatility alone may not always be a good measure of market quality.\nOther interesting results include the fact that a more diuse prior on the value of the stock can lead to better learning in the market.\nThis is because, when the traders have less belief in their initial information, they have a greater incentive to glean knowledge from the better informed market as a whole.\nThe authors model allows for another interesting experiment.\nOne of the parameters of their model is the threshold level at which a trade between two agents is noticed by other traders.\nTrades which are smaller than this threshold level go unnoticed, but the larger trades are observed.\nThe authors nd that reducing this threshold reduces price volatility and increases forecast accuracy.\nThis is again suggests that, in the end, the learning processes in this sequential market are eective although not perfect.", "The markets discussed in this section emphasize the replication of many of the empirical puzzles that were mentioned at the beginning of this chapter.\nIn each case the agent-based model itself is less important than the replication of various empirical results from nancial market time series.\n3.4.1 Memory and return autocorrelations", "Levy, Levy & Solomon (1994) presents a nancial market model with outcomes emerging from agent strategiest.39 Similar to the market models covered above, these outcomes depend on the presence of many dierent heterogeneous agent types.\nHowever, the traders in Levy et al.\n(1994) do not form complicated strategies and predictors.\nTraders maximize a one-period myopic utility function exhibiting constant relative risk aversion rather than constant absolute risk aversion.\nThis technical change is important in that now agents impact on prices depend on their relative wealth levels.", "The economic foundations of the model are similar to other agent-based nancial markets.\nThere is a risk-free asset which pays a constant interest rate.\nThere is a risky stock paying a random dividend that follows a multiplicative random walk, dt+1 = dt(1 + zt+1), (23)", "where zt is drawn from a well-dened distribution designed to roughly replicate actual dividend growth.\nThe market consists of several types of traders.\nThere are fundamental traders who possess a model for pricing the stock based on the dividend fundamental.\nThey use this to predict the future price, and to then set their optimal portfolio fraction accordingly.\nA second, and more important, type for this model uses past information only to determine its current portfolio.\nThis trader looks at the past m periods of returns, and nds what fraction of stock and bond holdings would have been optimal over this period.\nThis is a kind of memory length for traders.\nIt allows for some to believe that only a short period of the past is necessary for forecasting, and others to a believe a much longer series is necessary.\nThe short-memory types represent a kind of short-term trader who is only interested in the latest fads and who believes the older returns data are irrelevant.40 The memory length history of past returns is used to make a portfolio recommendation for the next period.\nThere is often a population of these traders with many dierent memory lengths.", "The authors progressively add richer sets of the heterogeneous memory traders who trade along side the 39This model is presented in the book, Levy et al.\n(2000), which also contains useful summaries of many other agent-based markets.", "fundamental traders.\nFor sets with only one, or two memory types, the stock price dynamics clearly reect the memory length, in that distinct cycles are observed.\nHowever, when a full spectrum of these traders is added, the prices show no perceptible cycles, and display very realistic features.\nThe returns show relatively large positive autocorrelations at shorter horizons and negative autocorrelations at longer horizons.\nThe authors suggest that this is representative of actual markets, where it has been shown that stock returns demonstrate small positive autocorrelation over short horizons, but negative autocorrelation over longer horizons.41 Many empirical aspects of the model are explored, including large amounts of trading volume, and its positive correlation with volatility.\nThe market also is capable of endogenously generating market crashes.\nThe authors are also very concerned with the coexistence of both the fundamental strategy, and the nite-memory strategies.\nThey give some examples showing the two types can coexist with neither one evolutionarily driving the other out.42 The model has been criticized recently by Zschischang & Lux (2001).\nThese authors claim that some of the original results are sensitive to the initial conditions in the simulation.\nThey further indicate that the results may be sensitive to the number of agents in the simulation.\nThis critique is interesting, but it was done for a set of only three dierent memory lengths of traders, 10, 141, 256.\nIt remains to be seen if it has implications over more general distributions of memory length.", "One of the most interesting empirical features that various nancial market models try to replicate is the persistence of asset price volatility.\nWhile stock returns themselves are relatively uncorrelated, the squares or absolute values of returns are autocorrelatied, reecting a tendency for markets to move from periods of relative quiet to more turbulent periods.\nSignicant positive autocorrelations for absolute stock returns continue out a year or more, and decay at a rate which is slower than exponential.\nThis slow decay rate cannot be captured by traditional time series models, and may indicate the presence of fractional integration in volatility.43 The mere fact that volatility is persistent is puzzling enough, but the fact that it may be fractionally integrated presents a high hurdle for agent-based nancial markets to hit in terms of empirical replications.", "The model of Iori (2002) is interesting both in its structure and in its ability to t these facts.\nThe model 41See Hirshleifer (2001) for summaries of these empirical results.", "42In Levy et al.\n(2000) begin to explore some simple multi asset models.\nTheir goal is to begin to understand how well the predictions of the Capital Asset Pricing Model hold up in heterogeneous agent situations.\nTheir early ndings are supportive of the CAPM, but the model only allows heterogeneity to enter in a limited way, through mean expectations.", "43See Baillie et al.\n(1996) for an example of a fractionally integrated volatility process.\nAlso, see LeBaron (2001c) for further discussion of fractional integration in stock return series.", "is based on the spatial spread of information across traders.44 In this model each trader i in each period t receives a signal Yi,t that combines information about the decisions of this traders local neighbors.\nFor example,", "(i,j) Ji,jSj,t + Ai,t, (24) where Sj,t are the decisions of other traders in the neighborhood of i, and Ji,j controls the weighting and the neighborhood size, and i,t is a noise term.\nJi,j declines as the distance between i and j increases.\nThis signal is an input into a trader is nal decision to purchase or sell one share of the stock.\nThe interesting part of this decision is that agents are assumed to have a range of inaction on the signal.\nFor wt < Yi,t < wt there is no trade by agent i, and Si,t = 0.\nWhen the signal is less than wt, the agent sells one unit, Si,t = 1, and when the signal is greater than wt the agent buys one unit, Si,t = 1.\nIt is clear that the decisions of trader i in turn feed into the signals of other traders.\nThe traders belief formation and demand processes are iterated several times until there is convergence.\nThen the demands to buy and sell shares are calculated as the number of positive and negative values of Si,t, respectively, and are recorded as Dt and Zt.\nThere is a market-maker who covers the order imbalance and who adjusts the price using pt+1 = pt(Dt Zt).\n(25)", "Stock returns are measured as the log dierence of this price series, and the volatility is estimated with the absolute values of these returns.\nThe model generates returns that are nearly uncorrelated, but the volatility series generates a very persistent autocorrelation pattern which is similar to actual asset return data.\nFurther, the model is also able to display the strong positive correlation between trading volume and volatility that is observed in the data.\nIt also appears that the thresholding of the signals is critical for volatility clustering to occur.", "Kirman & Teyssiere (2001) develop another model capable of generating very persistent return volatility.\nIt is a modied version of Kirman (1991) which is described more extensively in Hommes (2005).\nThis model is a form of the earlier-mentioned few-type models in which agents follow a nite set of well-dened portfolio rules.\nThese are dened as technical and fundamental, and the traders shift back and forth between these according to an epidemiological process of contagion.\nThe authors perform extensive tests on the properties of returns generated by the model, and show good qualitative agreement with actual foreign exchange series 44Other examples of this type of model are discussed by Hommes (2005).\nThese examples include Cont & Bouchaud (2000) and Stauer & Sornette (1999).", "Several papers have taken the step of trying to tie markets to actual market fundamentals.\nIn Farmer & Joshi (2002) the authors use U.S. aggregate real dividends interpolated to daily frequencies as a fundamental input into market with heterogeneous value investors and trend followers.\nTheir nancial market model generates reasonable long swings away from the fundamental pricing as well as uncorrelated daily returns.\nIt also generates most of the important empirical features described in previous sections, including, fat tails, volatility persistence, and trading volume persistence.\nThe model also oers interesting tractability since it is built from a foundation of realistic trading strategies.", "LeBaron (2001a) and LeBaron (2002a) perform some extensive calibration exercises.\nThese exercises are based on an agent-based model presented in LeBaron (2001b).\nThis model combines several features of the models mentioned previously.\nIt uses a neural network structure to represent trader portfolio strategies.\nIn this model traders do not build forecasts.\nThe neural network maps past information directly into a recommended portfolio holding directly, and thus avoids the intermediate step of mapping a forecast into a portfolio policy.\nIt also avoids having to estimate the return variance using a separate volatility equation.\nTraders are dened by heterogeneous memory lengths as in Levy et al.\n(1994).\nSome traders evaluate strategies using a short past history of returns, while others use longer histories.\nAlso, the preferences for the agents are constant relative risk aversion, so agents with more wealth control a larger fraction of the market.\nThe strategy population evolves separately from the traders; the traders choose strategies perceived to be optimal based on time series with lengths corresponding to the traders memory lengths.\nThis has some similarities to the social learning mechanisms in Chen & Yeh (2001).\nThe strategies are evolved using a modied genetic algorithm designed to respect the neural network architecture.\nFinally, the economic structure is similar to many of the nancial market models reviewed above in that there are only two traded assets, a risky asset and a risk-free asset.\nThe risky asset pays a well-dened stochastic dividend following a geometric random walk with drift and volatility calibrated to match aggregate U.S. dividends.\nThe time period in the model is set to 1 week.", "The model is compared with values drawn from the S&P 500, and it is able to replicate a large range of features quantitatively.\nThese range from simple statistics, such as means and variances of returns, to the more complicated dynamic features of volatility persistence, and volatility/volume cross correlations.45 45An interesting feature is that the model replicates the tendency for volatility to lead trading volume.\nThis is consistent These results appears to be connected to the presence of short-memory traders.\nEliminating the latter group leads the market to converge to a well-dened rational expectations equilibrium.\nOther modications are shown to improve learning and to induce the market to converge.\nAmong these are slowing down the rate at which agents switch rules, and having them switch strategies only when a new strategy beats the current one by a certain threshold [LeBaron (2002b)].\nBoth of these operate to slow down the learning process, which one would think would make things worse.", "The strategies used in this market are emergent in that they are not prewired into the model.\nIt is interesting to note that the learning process does evolve as the market progresses.\nLeBaron (2001a) shows that in the early stages of the market, predictability is quite high.\nRegressions of returns on simple lagged returns can yield R-squared values as high as 0.7.\nThese patterns are quickly learned by agents, however, and this unrealistically high predictability is greatly reduced.\nIt is also interesting that the dividend-price ratio remains a consistently good predictor in many dierent time periods, which is consistent with results from real nancial data.", "Bullard & Duy (2001) introduce learning into a more traditional macroeconomic framework for asset prices.\nThe model is a multiperiod overlapping generations setup with a constant returns to scale aggregate production technology.\nAlso, important is the fact that the government issues money in the economy at a constant growth rate that is greater than the growth rate of the economy.\nTherefore, the forecasting of ination and real returns becomes an important problem for agents in this economy.\nThey forecast future price levels using a recursive regression framework.\nThis learning mechanism yields excess volatility in the asset market.\nThe authors perform a search over their parameter space using a genetic algorithm to nd parameters generating results similar to actual data.\nThey nd parameter values that are able to give them reasonable volatility in asset returns along with a low volatility in per capita consumption growth.\nFor the most part, the parameter values that generate these results are consistent with U.S. macroeconomic data.\n3.4.4 Other calibration examples", "This section briey summarizes several other calibration examples which try to line up with interesting data sets, and scrutinize time series generated by agent-based nancial markets.\nArifovic & Masson (1999) implement an agent-based model of foreign exchange currency crises which is aligned with empirical results from foreign exchange crises periods.\nAnother model examining foreign exchange markets is Marey (2004) which uses foreign exchange survey forecasts to calibrate agent behavior.\nFinally, several papers such as Chen, with results in Gallant et al.\n(1993).", "Lux & Marchesi (2001) and Arifovic & Gencay (2000) perform detailed tests on the nonlinear properties of the time series output from various agent-based nancial markets.\nThey general nd evidence similar to that from actual markets.", "While many market models have been calibrated to nancial time series, very few computational models have attempted to actually t parameters to data in a direct estimation procedure.\nObviously, in most computational models this will be a costly procedure in terms of computer time.\nA recent exception to this is Winker & Gilli (2001) where the authors estimate parameters in the Kirman (1991) model.\nThey search over two parameters in the model with an objective of tting two features of actual nancial returns, kurtosis, and the rst order volatility coecient in an ARCH(1) specication.\nSince the search space and objective are relatively simple, this paper provides the most detailed view into the sensitivity of the results to various parameter specications.", "Estimation of few-type models has been a much more common activity, and has already yielded some interesting early results.\nThe simpler structure of these models permits their conversion into tractable, albeit nonlinear, time series structures.\nVigfusson (1997) is one of the rst papers to estimate one of these models.\nThe framework is based on a model by Frankel & Froot (1988) for studying exchange rate movements, which was mentioned in section 3.1 and is also covered by Hommes (2005).\nThe model is implemented empirically as a Markov switching model, as in Engel & Hamilton (1990), where the two states correspond to fundamental and chartist regimes.\nExchange rate predictions are generated as a weighted average of the two dierent regimes, where the weights are given by conditional probabilities of the two states.\nSome general support is given to the dierent conditional forecasts in dierent states of the world, but some of the results are mixed.\nAhrens & Reitz (2005) is a more recent test of a Markov switching model.\nThey nd better evidence in favor of the model with chartists and fundamentalists, and they also test several dierent specications for the chartist regime.\nThey see an interesting connection between volatility and the types of traders, and many of these results appear robust across dierent subsamples.\nThey also document an interesting result that volatility is larger during the fundamental regime.\nThis result is interesting, but a little dicult to explain.\nWesterho & Reitz (2003) and Reitz & Westerho (2004) t a nonlinear threshold model of a nancial market to various time series.\nThis model is also inspired by the few-type models with chartists and fundamentalists trading in a market.\nThe model results are generally supportive of the transition between the two dierent types of trading strategies.\nThey nd dierent market dynamics depending on how close the price is to fundamental value.\nThese are an interesting rst test of heterogeneous trader behavior.\nMore extensive tests will be necessary to judge the general robustness of this modeling framework.", "A common concern about all agent-based computational modeling is validation.\nThe usual criticism leveled at agent-based nancial markets is that there are too many degrees of freedom.\nResearchers are able not just to move freely through large parameter spaces, but can also change entire internal mechanisms at their discretion in the attempt to t sets of stylized facts.\nAnyone using agent-based nancial markets must acknowledge that there is some truth to these criticisms.\nHowever, these comments should not stop all experimentation.\nFurthermore, there are directions in which the eld is moving that will give these markets a more solid foundation.", "Some steps that researchers can take to ameliorate these problems include replicating dicult empirical features, putting parameters under evolutionary control, and using results from experimental markets.\nThe rst of these suggestions involves making sure that an agent-based nancial market ts facts which are not well replicated by standard models.\nExamples of this would be empirical features such as the long range persistence of volume and volatility in nancial time series.\nThis requirement sets a higher standard for empirical replication, and also pushes the envelope in terms of our understanding about which mechanisms may be at work in nancial markets.46 The second suggestion is to put as many parameters as possible in the market under evolutionary control.\nAn example of this change is reected in the dierences between markets such as the SF-ASM, and LeBaron (2001b).\nIn the rst case xed learning rates for all traders implicitly give them a common perspective on how much past data is allowed into tness evaluation.\nIt turns out that this parameter is crucial to the behavior of the market.\nIn the second case, traders with dierent perspectives on the past compete against eachother.\nIf there were an optimal memory length of past data to use, this would dominate the market in terms of wealth.\nThus the setting of this eective value of this parameter is reected in the wealth distribution of traders in the model, and is part of the evolutionary dynamics.\nThe nal suggestion would be to use results from experimental economics to build better, and more realistic learning dynamics in the articial nancial markets.\nThis seems like a promising procedure, but as yet there are not that many examples of it.47", "46An extension of this is to concentrate model tting on extreme event periods in the market as in Ecemis, Bonabeau & Ashburn (2005).", "47Duy (2005) surveys agent-based models and experimental work.\nThere are several examples given there of agent-based learning mechanisms which t experimental data.\nWhether such mechanisms could be taken into settings that are more complicated that the human experimental settings is an interesting and open question.", "This sections covers several nancial market models which are dierent from those considered above.\nAmong these are markets which consider detailed trading institutions and learning market makers, and also models which consider the coevolution of strategies and nancial securities.", "Most of the markets considered up to now have abstracted away from actual trading institutions.\nThis is somewhat of a puzzle in the agent-based nance world, since a bottom up approach would appear to call for starting from the basics of how trades are executed.\nMost models build stylized economic structures that avoid the institutional details of trading.\nHowever, research has begun appearing which implements more realistic trading systems.48 Market design and market microstructure questions appear to be well suited for agent-based approaches.\nFirst, large amount of data are available.\nSecond, there are critical policy questions which clearly need to be tested in an environment with heterogeneous, adaptive strategies.\nSince some of this area is covered in other handbook chapters, the descriptions of models here will be relatively brief.", "It is interesting that Rieck (1994), one of the earliest agent-based nancial market studies, species the trading process in detail.\nRieck (1994) looks at the evolution of trading strategies with a simple order-book trading mechanism.\nHis model has many similarities to some of the emergence papers mentioned in the previous sections in that the coevolution of strategies is the crucial issue of interest.\nAlso, strategies are evolved using evolutionary techniques, but these are applied to functional forms that are designed to replicate actual trading strategies.\nHis results show that fundamental strategies are not able to take over the market and drive the price to the fundamental value.\nRieck (1994)s ndings suggest that many results obtianed in agent-based nancial market models without detailed specications for trading strategies could be replicated using more empirically-based micro trading mechanisms.49 Much simpler models have been implemented using an order-book trading mechanism with the goal of replicating empirical features of actual market data.\nOne example of this is Chiarella & Iori (2002).\nThis is a few-type model with technical, fundamental, and noise traders placing orders in an electronic order book system.\nThey show that the interaction of these three types generates realistic price series, and trading activity.\nJust how much agent complication is necessary to replicate high frequency features in nancial time series is a question which is addressed in Farmer et al.\n(2005).\nThis is not exactly an agent-based market since order ow is completely random and there is no individual trading agent per se.\nRandom order ow 48This area of nancial research overlaps with work on market design which is covered more extensively in Mackie-Mason & Wellman (2005) and Marks (2005).", "is calibrated to the actual order ow for several dierent stocks on the London Stock Exchange.\nThis ow is then fed into a market clearing mechanism with a standard electronic order book.\nThe types of incoming orders, limit or market, are determined randomly and calibrated to the actual order ow from the data.\nEven though traders in this model have no learning capabilities, the authors are able to show that the outcomes of their model replicate many feature from actual price history data sets.\nAs in the work by Gode & Sunder (1993) on zero intelligence traders, these results help us to understand which empirical regularities are the result of learning behavior, and which are simply a feature of the trading institution.50 One of the most well documented features in intra-day data is the U-shaped pattern in bid ask spreads which are wide at the opening of trading, narrow during the day, and again widen before the close.\nThere are also similar patterns in the volatility of spreads, return volatility, and trading volume as well.\nChakrabarti (1999) seeks to replicate these features in a microstructure trading model that uses an agent-based framework for foreign exchange dealers.\nDealers receive random order ow through the day which gives them information about the aggregate order ow, and the eventual value of the foreign currency they are dealing in.\nThis information is augmented by quotes they receive from other dealers during the intra-day trading period.\nDealers are risk averse and are concerned about variances of their positions during the day, and also on the positions they hold overnight.\nThe reservation prices for these dealers are determined in a Bayesian learning framework.\nEach dealer determines an optimal selling (ask) and buying (bid) price at each time step.\nThe spread between these is the return that compensates the dealer for risk in the inventory position.\nTrade takes place in a random matching process of the dealers.\nThey trade when a calling dealers bid is greater than the responding dealers ask, or when the calling dealers ask is less than the responding dealers bid.\nDealers use information from the other dealer spreads to update their own beliefs about order ow as they move through the day.\nAs trading proceeds, all traders information improves, and order ow uncertainty falls.\nThis leads to smaller spreads from the morning into the day.\nAs the day reaches the close, the impact of overnight risk takes over for the dealers and spreads rise again.", "The model is simulated for a wide range of parameters values.\nThe author chooses 729 unique parameter value combinations, performs simulation runs for each combination o parameters values and records their results as separate observations.\nParameter sensitivity is then determined using least squared regressions.\nThe results show a general presence of the U-shaped spreads of return volatility over the simulated trading 50A very early example of this type of research on random order ow is Cohen, Maier, Schwartz & Whitcomb (1983).\nAnother recent research direction has been to link electronic trading agents to live data feeds coming o of actual markets.\nIn the PennLehman Trading Project, Kearns & Ortiz (November/December 2003) the survival of dierent strategies can be monitored as they interact with live market data.", "days, and these results are robust across many of the tested parameter combinations.\nAn interesting general result is that there is more unexplained variation in the afternoon variables.\nThe author conjectures that this indicates the importance of path dependence of the prices and trades executed through the day.\nFinally, the nonlinear impact of the parameter values on the results is explored.\nIn most cases there are signicant nonlinear eects in both quadratic and cross terms.\nThis suggests a very complex relationship connecting the underlying information and preference parameters to nal market outcomes.", "Most nancial markets depend critically on the behavior of a market maker, or dealer, who brings liquidity and continuity to a real time trading market.\nSeveral agent-based models explore the behavior of dealers.\nGu (1995) takes the model of Day & Huang (1990) and explores changing the market maker behavior built into the model.\nThis analysis includes estimating the market maker protability under dierent parameters.\nThe results show that a prot-maximizing specialist may be interested in generating some amount of extra market churning.\nThe specialists objectives will not align with price variance minimization which could be construed as the maintenance of an orderly market.\nWesterho (2003c) also explores the impact of inventory restrictions in a setup with an implied market maker.\nThe market maker price adjustment reactions dier depending on the current inventory position along with current excess demands.\nThe market maker is assumed to make greater price adjustments when these two variables are of the same sign.\nIncreasing this adjustment level leads to increased volatility.\nAlthough interesting, this result does depend critically on very specic behavioral assumptions made for the market maker.51 Most of the papers considered in this survey could loosely be considered part of the investment side of nance.\nThere is no consideration for the issuance of securities by rms, or the design and evolution of securities themselves.\nA recent exception is Noe, Rebello & Wang (2003) which represents the rst paper to consider corporate nance issues in an agent-based framework.\nThe authors are interested in the problem of which securities rms will issue to raise investment capital, and how investors learn to price these securities.\nFirms need to issue securities that maximize their prots, but cannot do this independent of investors pricing strategies.\nOn the other hand, investors must learn how to price and evaluate the securities issued by rms, but they can only do this for securities they have seen in the past.\nThe importance of this coevolutionary process of rm and investor learning turns out to be critical in the authors model.", "In Noe et al.\n(2003) a rm has an investment project that needs to be nanced, and there are two potential 51A related paper is Chan & Shelton (2001) which models a dealer learning optimal behavior when faced with a random order ow.\nFurther research in the area of market design includes papers examining tick sizes (Darley, Outkin, Plate & Gao (2000) and Yeh (2003)), order book versus dealer markets (Audet, Gravelle & Yang (2001), and price limits, trading taxes, and central bank intervention (Westerho (2003b), Westerho (2003d), and Westerho (2003a).", "investors.\nThe rm can chose from a xed set of six dierent securities that it can issue.\nThese include standard debt and equity securities, along with some more complex ones.\nThe latter include convertible and subordinated debt, as well as something known as ado-or-die security.\nIn each case the security represents a well-dened contract for splitting the payout to the rms risky project between the rm and the two investors.\nBoth the rm and investors encode their strategies as bitstrings for use with a GA. The rm maintains a pool of 80 potential security issue decisions which is a vector of numbers (binary coded) between one and six corresponding to the six types of securities.\nThe rm will chose one of these at random each period.\nThe tness of a strategy is updated with the realized cash ow received by the rm after the investment project has been completed and the investors have been paid.\nEvolution takes place by replacing all the rules that encode the least protable strategies with rules that encode the most protable strategy.\nThen a mutation operator is applied to all rules.", "The investors are encoded as bitstrings.\nThe two investors maintain a price table that indicates the price that they will pay for each possible security.\nThe investor has a table of 80 possible pricing strategies for each security.\nIn each round, each investor choses a pricing strategy at random from the appropriate security table after the rm has decided on the security that it will issue.52 The security goes to the highest bidder in each round.\nThe protability of the strategy from the investors perspective is recorded, and the populations are adjusted with a selection procedure in which the 10 worst strategies are replaced by the 10 best.\nAt this point the GA is applied to the population with crossover, mutation, and the election operator.", "The authors then run this simulation for many rounds and in many dierent design situations.\nOne of the most interesting results comes from the choice of securities.\nExperiments are performed that try to separate out the joint learning processes.\nFirms play against a xed set of investors who know the appropriate pricing functions.\nIn this situation equity and subordinated debt dominate the market, and straight debt is rarely used in stark contrast to the real world.\nWhen learning is allowed for both parties, debt moves to becoming the most commonly used security, with subordinated debt next, and equity third.\nThis shows the importance of the coevolutionary learning dynamic.\nIn this world the preponderance of debt may have more to do with the ability of rms to learn how to price this relatively simple security, and the ensuing positive feedback this has on the issuance decision.\nSeveral other results from the model are also interesting.\nInvestors tend to systematically underprice the securities in all cases.\nAlso, the situation where the rm is not able to raise sucient investment funds actually occurs more often with two-sided learning than investor-only learning.", "The results in this paper will eventually need to be explored under dierent learning specications and 52As in the earlier GA papers there is a binary-to-real mapping that determines the real valued price.", "investment structures, but it is an interesting rst attempt to use agent-based models in the eld of corporate nance.\nThe coevolution of agent behavior along with the institutions that guide this behavior is interesting both for nance and for economics in general.", "One nal agent-based model which is often compared to nancial markets is the minority game.53 This is a repeated game in which agents must chose one of two doors, left or right.\nIf the minority of agents choses left this group wins, and if the minority chose right this group wins.\nThe connection to nance is through the notion of contrarian strategies, where it is best to move against the herd.\nConnecting this model to nance is a controversial subject since its basic version does not have a natural role for prices.\nAlso, it would appear that the contrary nature of the minority game is somewhat forced, and in real nancial markets it may be better to follow the herd for a short period of time.\nAn interesting application of the minority game to nancial data is Johnson, Lamper, Jeeries, Hart & Howison (2001).\nIn this model the authors convert a nancial series into a binary string depending on whether the price rises or falls.\nThe agents play the game for many periods watching, the real nancial time series as the input into their rule selection process.\nThe agents are then allowed to continue playing the game after the price series is shut o, and the continued model dynamics are used in a kind of out of sample forecasting context.\nThey are able to produce some small forecasting gains in some high frequency data.\nIt remains to be seen how robust and reliable these numbers are, but this is an interesting test of the minority game model on real data.54", "Agent-based markets have been criticized from many dierent angles.\nThe most common criticism is that the models have far too many parameters, and the impact of many of these parameters is not well understood.\nThis issue has already been discussed in the section on calibration.\nHowever, beyond simple parameter questions, these models have made use of a wide selection of the available computational tools and methods.\nTable 1 gives a short overview of the design structures of some of the agent-based nancial market models described in this paper.\nThis is far from being an all inclusive list, since many of the models described in this chapter would not t well into the criteria for the list.\nThis emphasizes what should have become clear from the earlier sections: agent-based nancial models have been built using many dierent features and designs.\nThis is natural for a eld at this early stage, but it has made comparisons across market platforms dicult.", "53There are several early implementations of this model.\nThese include Arthur (1994), and Challet & Zhang (1997).\nHowever, early versions of similar models can be found in Schelling (1978).\nSee Jeeries, Hart, Hui & Johnson (2000) for a recent survey.\nInterested readers should go to the website for the minority game at http://www.unifr.ch/econophysics/minority/.", "54Another agent-based model indirectly related to nance is the resource allocation setup in Youssefmir & Huberman (1997).", "Unlike analytic models, there are still relatively few general principles that one can condently apply to the construction of dierent agent-based market models.\nThis is a problem, but the situation should improve as the eld evolves.", "(Insert table 1 about here.) Another important issue that is brought up is the stability of a given agent-based models results to the addition of new trading strategies.\nSpecically, are there strategies that would smoke out obvious patterns in the data and change the dynamics?\nAgent-based models are trying to continuously defend against this with the continuously learning agents, but something outside the learning structure is possible.\nAn initial defense of this is that most markets generate very little autocorrelation and therefore yield no obvious arbitrage opportunities for new trading strategies to exploit.\nHowever, there is a possibility that more complex nonlinear strategies could detect such opportunities.\nArifovic (2001) is an example testing this sort of issue, and nds that the more complicated agents do not do better in her simulated market environment.\nThis problem is still one of the most important for agent-based modelers to worry about, and no one should feel immune to this criticism.", "Another very common and pertinent criticism is that most agent-based nancial market models assume a small number of assets.\nOften agents trade only one risky asset, and one risk-free asset alone.55 It is certainly true that, with all of the new methodological tools in use in these models, it was important to start with the simplifying case of one risky and one risk-free asset.\nHowever, this simplication may eliminate many interesting features.\nThe criticisms of models with a single representative agent may carry over equally well to models with a single representative risky asset.\nQuestions naturally arise about calibrating to aggregate dividends, and exactly what this calibration means, since aggregate dividends are not paid by any single stock.\nAlso, recent events such as the technology bubble of the 1990s remind us that bubbles are often very sector dependent.\nFinally, when thinking about trading volume, it is really necessary to have a multi-asset world where traders are allowed to move back and forth between stocks.\nThe single asset market puts an extreme restriction on the amount of trading volume that can be generated in a simulated market.\nAnother related problem is that, even though most agent-based markets have two assets, they actually shut down pricing in one market.\nIn many cases the risk-free rate is xed, hence the market is not a general equilibrium model.\nThis is problematic in that explaining the level and volatility of the risk-free asset itself has been another asset pricing puzzle.\nGetting the risk-free rate to be as low and stable as it is in actual macro 55Two recent exceptions to this are Chiarella, Dieci & l. Gardini (2004) and Westerho (forthcoming 2004).\nAlso, Levy et al.\n(2000) perform some experiments in multi-asset settings with options.", "data is not easy, and most agent-based models simply avoid this problem completely.\nEndogenously opening multiple markets for trading is still a dicult problem, but it needs to be addressed at some point.\nOnce researchers are more condent they have mastered agent-based modeling tools, they will probably tackle multi-asset market modeling more frequently.", "Egenter, Lux & Stauer (1999) address another interesting question for agent-based modelers to consider.\nWhat happens as the number of agents is increased?\nThey have performed some tests on models that can be studied analytically, and they nd that the dynamics can change dramatically as the number of agents becomes large.\nWhat initially looks like random behavior for a small numbers of agents can become increasingly predictable as the number of agents becomes very large.\nIs it possible that many of the nice features that many models display are artifacts of the limitation to relatively small numbers of traders imposed by computer modeling?\nThis is a very important question.\nOne response to this question is that assuming an innite number of agents might not be realistic in some settings.\nThere may be real-world market situations in which the thinness of the market is an important and critical issue for the determination of the markets dynamics.\nThis issue will denitely be an important one for the eld to tackle in the future.", "Almost all of the agents that are modeled and discussed in this survey operate inductively.\nThey adopt rules and forecasts which have performed well in the recent past, and they adjust these rules and forecasts to perform better in the future.\nThe early spirit of agent-based models is clearly to push away from more traditional deductive styles of learning and towards more inductive styles of learning.\nHowever, it is often asked if there still may be a role for some form of deductive reasoning.\nIs it going too far to think of agents simply looking for patterns in the past and using behaviors that have worked in the past?\nCan they be allowed to do some form of deductive reasoning?\nCan they learn commonly held theories in nance, such as present value analysis, or the Black-Scholes option pricing formula?\nAn interesting question is whether an agent-based model can be constructed that allows for a little deductive reasoning while keeping the general inductive spirit of simple rules of thumb.", "A nal problem, often ignored, is timing.\nAlmost all agent-based models need to make explicit assumptions about the timing of decisions, information, and trade.\nOf course, any asset pricing model needs to make these choices, but in analytic settings more events can be assumed to take place simultaneously.\nIn the computer this sequence of events often needs to be spelled out.\nThe degree to which results depend on arbitrary timing decisions is denitely important.\nOne example that has been discussed here is the delayed price adjustment approach, where prices are adjusted based on current excess demand in the market.\nIt is important to note that in a world of evolving strategies, this timing may have a large impact since the strategies themselves adapt to the specic timing and trading structures.\nIt will be interesting to see if agent-based nancial models start permitting actions to take place more asynchronously, and if this has an impact on any of the early results.", "This paper has given an overview of the current state of research in agent-based computational nance along with some ideas concerning the design and construction of working simulations.\nIt is important to note that this is a very young eld, and it still shows the kind of open-ended exploratory nature of such an endeavor.\nHowever, several crucial trends are starting to appear.", "First, the models are beginning to divide into several dierent types.\nThese range from the few-type models covered in section 3.1, in which traders are assumed to choose from among relatively small xed sets of trading strategies, to the many-type models covered in sections 3.2 and 3.3 in which traders choose from among large and possibly evolving sets of trading strategies.\nThe few-type models oer an important dimension of tractability relative to the the many-type models, and they often provide denitive connections between parameters and results which might not be seen or noticed in the more complex frameworks, so it is easy to see their appeal.\nHowever, a key reason for doing computer modeling is that the use of more sophisticated trading strategies in many-type models needs to be understood as well.\nThere are two basic reasons for this.\nFirst, many-type models take emergence very seriously in that they do not bias toward any particular strategy loaded ex ante by the researcher.\nThe strategies that end up being used are those that appear and persist inside a learning structure.\nThey therefore partially answer a criticism of the few-type models that their specication of trading strategies is ad hoc. Second, they use the computer and the learning algorithms to continuously search the time series record to smoke out new trading opportunities.\nThis is something that is not present in the few-type models.\nThe obvious limitation is that their ability to seek out and take advantage of any ineciencies that may appear depends critically on the data representations and implementations of the learning algorithms.\nFew-type and many-type models clearly each have both strengths and weaknesses that users should take into account.", "Up to this point very little reference has been made to the growing literature on behavioral nance.\nIt is important to dene where agent-based nancial markets sit relative to this larger eld.\nFirst, they are clearly behavioral models themselves, since the agents are boundedly rational and follow simple rules of thumb.\nThis is a key characteristic of any behavioral model, and agent-based models have this characteristic.\nWhere agent-based nancial market models have diverged to date from behavioral nance models is their typical presumption that agent preferences have relatively standard representations.\nTypically, no attempt is made to model common behavioral biases such as loss aversion or hyperbolic discounting.\nThis is not because agent-based models cannot handle these behavioral aspects.\nRather, it has just seemed sensible in this early stage of the eld to refrain from adding too many more complications to models which are already very complicated.\nIt is important to note that agent-based technologies are well suited for testing behavioral theories.\nThey can answer two key questions that should be asked of any behavioral structure.\nFirst, how well do behavioral biases hold up under aggregation; and second, which types of biases will survive in a coevolutionary struggle against others.\nTherefore, the connections between agent-based approaches and behavioral approaches will probably become more intertwined as both elds progress.", "Whether computational or not, all of the models mentioned in this survey share a common tie to ideas from nonlinear dynamics and chaos.\nThe relationship between model structure and noise in nonlinear systems can be very complicated, and these markets share this feature.\nIn many cases the markets operate as noise magniers, taking a small amount of input noise, or underlying fundamental risk, and increasing its level to a much larger observed macro value.\nNoise can also help to stabilize a nonlinear system by keeping it o unstable trajectories.\nAs is well known, nonlinear systems can also be dicult to forecast, and most of the markets described here share this feature.\nUnfortunately, this may also make them dicult to estimate using traditional econometric tools.\nAgent-based modelers should be aware of these nonlinear issues, and take them into account when evaluating market simulations.", "Agent-based modelers are also starting to move from the more stylized earlier nancial market models toward more models incorporating explicit market microstructure.\nThe latter try to model very explicitly the actual mechanisms of trade that are being used in the market as opposed to building a stylized trading framework.\nThese microstructure oriented models are well designed to answer questions concerning the construction and design of these same trading mechanisms.\nIn some of these markets it is the institutions that are at the center of the investigation, and the agents are just a mechanism for testing their behavior.\nSome of the policy questions addressed in this work are much more sharply dened than in other agent-based models.\nAn example of this would be the explorations into decimalization on markets, or the implementation of price limits.\nFrom a policy perspective this would seem to be a very natural place for the eld to move as it matures.", "Financial markets are an important challenge for agent-based computational modelers.\nFinancial markets may be one of the important early areas where agent-based methods show their worth, for two basic reasons.", "First, the area has many open questions that more standard modeling approaches have not been able to resolve.\nSecond there is a large amount of nancial data available for testing.\nIt will be interesting to see if, sometime in the future, nancial economists eventually replace the stylized theories of equilibrium market dynamics with a more realistic picture of the continuing struggle of learning and adapting agents who push markets in the direction of eciency, even though they never quite reach this goal.", "Ahrens, R. & Reitz, S. (2005), Heterogeneous expectations in the foreign exchange market: Evidence from daily DM/US dollar exchange rates, Journal of Evolutionary Economics 15, 6582.", "Albin, P. S. & Foley, D. K. (1992), Decentralized, dispersed exchange without and auctioneer: A simulation study, Journal of Economic Behavior and Organization 18(1), 2752.", "Alchian, A.\n(1950), Uncertainty, evolution, and economic theory, Journal of Political Economy 58, 211221.", "Allen, F. & Karjalainen, R. (1998), Evolution of trading rules in nancial markets, Journal of Financial Economics 51, 245271.", "Andersen, T. G., Bollerslev, T., Diebold, F. X.\n& Labys, P. (2003), Modeling and forecasting realized volatility, Econometrica 71, 529626.", "Arifovic, J.\n(1994), Genetic algorithm learning and the cobweb model, Journal of Economic Dynamics and Control 18, 328.", "Arifovic, J.\n(1996), The behavior of the exchange rate in the genetic algorithm and experimental economies,", "Arifovic, J.\n(2001), Performance of rational and boundedly rational agents in a model with persistent exchange rate volatility, Macroeconomic Dynamics 5, 204224.", "Arifovic, J.\n& Gencay, R. (2000), Statistical properties of genetic learning in a model of exchange rate,", "Arifovic, J.\n& Masson, P. (1999), Heterogeneity and evolution of expectations in a model of currency crisis, Technical report, Simon Fraser University, Vancouver, BC, Canada.", "Arthur, W. B.\n(1994), Inductive reasoning and bounded rationality, American Economic Review 84, 406 411.", "Arthur, W. B., Holland, J., LeBaron, B., Palmer, R. & Tayler, P. (1997), Asset pricing under endogenous expectations in an articial stock market, in W. B. Arthur, S. Durlauf & D. Lane, eds, The Economy as an Evolving Complex System II, Addison-Wesley, Reading, MA, pp.\n1544.", "Audet, N., Gravelle, T. & Yang, J.\n(2001), Optimal market structure: Does one shoe t all?, Technical report, Bank of Canada, Ottawa, CA.", "Bachelier, L. (1900), Theorie de la Speculation, PhD thesis, Ecole Normale Superieure, Paris, France.", "Badegruber, T. (2003), Agent-based Computational Economics: New aspects in learning speed and convergence in the Santa Fe Articial Stock Market, PhD thesis, Universitat Graz, Graz, Austria.", "Baillie, R. T., Bollerslev, T. & Mikkelsen, H.-O.\n(1996), Fractionally integrated generalized autoregressive conditional heteroskedasticity, Journal of Econometrics 74, 330.", "Bansal, R. & Yaron, A.\n(2004), Risks for the long run: A potential resolution of asset pricing puzzles,", "Barber, B.\n& Odean, T. (2000), Trading is hazardous to your wealth: The common stock investment performance of individual investors, Journal of Finance 55, 773806.", "Barberis, N. & Thaler, R. (2002), A survey of behavioral nance, in G. Constantinides, M. Harris & R. Stulz, eds, Handbook of Economics and Finance, North-Holland.", "Beja, A.\n& Goldman, M. B.\n(1980), On the dynamic behavior of prices in disequilibrium, Journal of Finance", "Beltratti, A.\n& Margarita, S. (1992), Evolution of trading strategies among heterogeneous articial economic agents, in J. A. Meyer, H. L. Roitblat & S. W. Wilson, eds, From Animals to Animats 2, MIT Press, Cambridge, MA.", "Beltratti, A., Margarita, S. & Terna, P. (1996), Neural Networks for economic and nancial modeling, International Thomson Computer Press, London, UK.", "Benink, H. & Bossaerts, P. (2001), An exploration of neo-Austrian theory applied to nancial markets, Journal of Finance 56(3), 10111027.", "Bollerslev, T., Engle, R. F. & Nelson, D. B.\n(1995), ARCH models, in Handbook of Econometrics, Vol.\n4, North-Holland, New York, NY.", "Bray, M. (1982), Learning, estimation, and the stability of rational expectations, Journal of Economic Theory 26, 318339.", "Breedon, D. (1979), An intertemporal asset pricing model with stochastic consumption and investment,", "Brenner, T. (2005), Agent learning representation: Advice on modeling economic learning, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "Brock, W. A.\n& Hommes, C. H. (1998), Heterogeneous beliefs and routes to chaos in a simple asset pricing model, Journal of Economic Dynamics and Control 22(8-9), 12351274.", "Brock, W. A., Lakonishok, J.\n& LeBaron, B.\n(1992), Simple technical trading rules and the stochastic properties of stock returns, Journal of Finance 47, 17311764.", "Campbell, J., Grossman, S. J.\n& Wang, J.\n(1993), Trading volume and serial correlation in stock returns,", "Campbell, J. Y.\n& Cochrane, J. H. (1999), By force of habit: A consumption-based explanation of aggregate stock market behavior, Journal of Political Economy 107, 205251.", "Campbell, J. Y., Lo, A. W. & MacKinlay, A. C. (1996), The Econometrics of Financial Markets, Princeton University Press, Princeton, NJ.", "Campbell, J. Y.\n& Shiller, R. (1988), The dividend-price ratio and expectations of future dividends and discount factors, Review of Financial Studies 1, 195227.", "Chakrabarti, R. (1999), Just another day in the inter-bank foreign exchange market, Journal of Financial Economics 56(1), 2964.", "Chakrabarti, R. & Roll, R. (1999), Learning from others, reacting and market quality, Journal of Financial Markets 2, 153178.", "Challet, D. & Zhang, Y. C. (1997), Emergence of cooperation and organization in an evolutionary game, Physica A 246, 407.", "Chen, S. H. & Yeh, C. H. (2001), Evolving traders and the business school with genetic programming: A new architecture of the agent-based articial stock market, Journal of Economic Dynamics and Control", "Chen, S., Lux, T. & Marchesi, M. (2001), Testing for non-linear structure in an articial nancial market,", "Chiarella, C. (1992), The dynamics of speculative behaviour, Annals of Operations Research 37, 101123.", "Chiarella, C., Dieci, R. & l. Gardini (2004), Diversication and dynamics of asset prices under heterogeneous beliefs, Technical report, University of Technology, Sydney, Australia.", "Chiarella, C. & Iori, G. (2002), A simulation analysis of the microstructure of double auction markets,", "Cohen, K. J., Maier, S. F., Schwartz, R. A.\n& Whitcomb, D. K. (1983), A simulation model of stock exchange trading, Simulation 41, 181191.", "Constantinides, G. M. (1989), Theory of valuation: Overview and recent developments, in S. Bhattacharya & G. M. Constantinides, eds, Theory of Valuation: Frontiers of Modern Financial Theory, Rowman and Littleeld, Totowa, New Jersey, pp.\n124.", "Cont, R. (2001), Empirical properties of asset returns: stylized facts and statistical issues, Quantitative Finance 1, 223236.", "Cont, R. & Bouchaud, J. P. (2000), Herd behavior and aggregate uctuations in nancial markets, Macroeconomic Dynamics 4, 170196.", "Dacorogna, M. M., Gencay, R., Muller, U. A., Olsen, R. B.\n& Pictet, O. V. (2001), An Introduction to High-Frequency Finance, Academic Press, San Diego, CA.", "Darley, V., Outkin, A., Plate, T. & Gao, F. (2000), Sixteenths or pennies?\nobservations from a simulation of the Nasdaq stock market, Technical report, Santa Fe Institute.", "Day, R. H. & Huang, W. H. (1990), Bulls, bears, and market sheep, Journal of Economic Behavior and Organization 14, 299330.", "De Grauwe, P., Dewachter, H. & Embrechts, M. (1993), Exchange Rate Theory: Chaotic Models of Foreign Exchange Markets, Blackwell, Oxford.", "DeLong, J. B., Shleifer, A., Summers, L. H. & Waldmann, R. (1990), Noise trader risk in nancial markets,", "Ding, Z., Granger, C. & Engle, R. F. (1993), A long memory property of stock market returns and a new model, Journal of Empirical Finance 1, 83106.", "Duy, J.\n(2005), Agent-based models and human subject experiments, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "Ecemis, I., Bonabeau, E. & Ashburn, T. (2005), Interactive estimation of agent-based nancial markets models:Modularity and learning, in Proceedings Genetic Evolutionary Computation Conference 2005, ACM Press.", "Egenter, E., Lux, T. & Stauer, D. (1999), Finite-size eects in monte-carlo simulations of two stock market models, Physica A 268, 250256.", "Ehrentreich, N. (forthcoming 2005), The Santa Fe articial stock market re-examined - suggested corrections, Journal of Economic Behavior and Organzization.", "Engel, C. & Hamilton, J. D. (1990), Long swings in the dollar: Are they in the data and do markets know it?\n, American Economic Review 80, 689713.", "Fama, E. F. (1970), Ecient capital markets: A review of theory and empirical work, Journal of Finance", "Fama, E. F. & French, K. R. (1992), The cross-section of expected stock returns, Journal of Finance", "Farmer, J. D. & Joshi, S. (2002), The price dynamics of common trading strategies, Journal of Economic Behavior and Organization 49, 149171.", "Farmer, J. D., Patelli, P. & Zovko, I.\n(2005), The predictive power of zero intelligence models in nancial markets, Proceedings of the National Academy of Sciences of the United States of America 102, 2254 2259.", "Figlewski, S. (1978), Market eciency in a market with heterogeneous information, Journal of Political Economy 86(4), 581597.", "Fogel, D. B.\n(1995), Evolutionary Computation: Toward a New Philosophy of Machine Intelligence, IEEE Press, Piscataway, NJ.", "Frankel, J. A.\n& Froot, K. A.\n(1988), Explaining the demand for dollars: International rates of return and the expectations of chartists and fundamentalists, in R. Chambers & P. Paarlberg, eds, Agriculture, Macroeconomics, and the Exchange Rate, Westview Press, Boulder, CO.", "Friedman, M. (1953), The case for exible exchange rates, in Essays in positive economics, University of Chicago Press, Chicago, IL.", "Fung, H. G. & Patterson, G. A.\n(1999), The dynamic relationship of volatility, volume, and market depth in currency futures markets, Journal of International Financial Markets, Institutions and Money 17, 33 59.", "Gallant, A. R., Rossi, P. E. & Tauchen, G. (1992), Stock prices and volume, The Review of Financial Studies 5, 199242.", "Gallant, A. R., Rossi, P. E. & Tauchen, G. (1993), Nonlinear dynamic structures, Econometrica 61, 871908.", "Gode, D. K. & Sunder, S. (1993), Allocative eciency of markets with zero intelligence traders, Journal of Political Economy 101, 11937.", "Goldberg, D. E. (1989), Genetic Algorithms in search, optimization and machine learning, Addison Wesley, Reading, MA.", "Grossman, S. & Stiglitz, J.\n(1980), On the impossibility of informationally ecient markets, American Economic Review 70, 393408.", "Gu, M. (1995), Market mediating behavior: An economic analysis of the security exchange specialists,", "Hansen, L. & Singleton, K. (1983), Stochastic consumption, risk aversion, and the temporal behavior of asset returns, Journal of Political Economy 91, 249265.", "Hirshleifer, D. (2001), Investor psychology and asset pricing, Journal of Finance 56(4), 15331597.", "Holland, J. H. (1975), Adaptation in Natural and Articial Systems, University of Michigan Press, Ann Arbor, MI.", "Holland, J. H., Holyoak, K. J., Nisbett, R. E. & Thagard, P. R. (1986), Induction, MIT Press, Cambridge, MA.", "Hommes, C. H. (2005), Heterogeneous agent models in economics and nance, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "Iori, G. (2002), A microsimulation of traders activities in the stock market: The role of heterogeneity, agents interactions and trade frictions, Journal of Economic Behavior and Organization 49, 269285.", "Jeeries, P., Hart, M., Hui, P. M. & Johnson, N. F. (2000), From market games to real-world markets, Technical report, Physics Deptartment, Oxford University, Oxford, UK.", "Johnson, N. F., Lamper, D., Jeeries, P., Hart, M. L. & Howison, S. (2001), Application of multi-agent games to the prediction of nancial time-series, Physica A 299, 222227.", "Joshi, S., Parker, J.\n& Bedau, M. A.\n(2000), Technical trading creates a prisoners dilema: Results from an agent-based model, in Computational Finance 99, MIT Press, Cambridge, MA, pp.\n465479.", "Kareken, J.\n& Wallace, N. (1981), On the indeterminacy of equilibrium exchange rates, Quarterly Journal of Economics 96, 207222.", "Kearns, M. & Ortiz, L. (November/December 2003), The Penn-Lehman automated trading project, IEEE Intelligent Systems pp.\n2231.", "Kim, G. & Markowitz, H. (1989), Investment rules, margin, and market volatility, Journal of Portfolio Management 16(1), 4552.", "Kirman, A. P. (1991), Epidemics of opinion and speculative bubbles in nancial markets, in M. Taylor, ed., Money and Financial Markets, Macmillan, London.", "Kirman, A. P. (1992), Whom or what does the representative individual represent?\n, Journal of Economic Perspectives 6, 117136.", "Kirman, A. P. & Teyssiere, G. (2001), Microeconomic models for long-memory in the volatility of nancial time series, Studies in Nonlinear Dynamics and Econometrics 5, 281302.", "Kocherlakota, N. (1996), The equity premium: Its still a puzzle, Journal of Economic Literature 34(1), 42 71.", "Koza, J. R. (1992), Genetic Programming: On the programming of computers by natural selection, MIT Press, Cambridge, MA.", "LeBaron, B.\n(1992), Some relations between volatility and serial correlations in stock market returns, Journal of Business 65(2), 199219.", "LeBaron, B.\n(2001a), Empirical regularities from interacting long and short memory investors in an agent based stock market, IEEE Transactions on Evolutionary Computation 5, 442455.", "LeBaron, B.\n(2001b), Evolution and time horizons in an agent based stock market, Macroeconomic Dynamics", "LeBaron, B.\n(2001c), Stochastic volatility as a simple generator of apparent nancial power laws and long memory, Quantitative Finance 1, 621631.", "LeBaron, B.\n(2002a), Calibrating an agent-based nancial market, Technical report, International Business School, Brandeis University, Waltham, MA.", "LeBaron, B.\n(2002b), Short-memory traders and their impact on group learning in nancial markets, Proceedings of the National Academy of Science: Colloquium 99(Supplement 3), 72017206.", "LeBaron, B.\n(forthcoming 2005), Building the Santa Fe articial stock market, in F. Luna & A. Perrone, eds, Agent-based Theory, Languages, and Experiments, Routledge Publishing.", "LeBaron, B., Arthur, W. B.\n& Palmer, R. (1999), Time series properties of an articial stock market,", "Lettau, M. (1997), Explaining the facts with adaptive agents: The case of mutual fund ows, Journal of Economic Dynamics and Control 21, 11171148.", "Levy, M., Levy, H. & Solomon, S. (1994), A microscopic model of the stock market: cycles, booms, and crashes, Economics Letters 45, 103111.", "Levy, M., Levy, H. & Solomon, S. (2000), Microscopic Simulation of Financial Markets, Academic Press, New York, NY.", "Lo, A. W. & MacKinlay, A. C. (1988), Stock prices do not follow random walks: Evidence from a simple specication test, Review of Financial Studies 1, 4166.", "Logato, I.\n& Velasco, C. (2000), Long memory in stock-market trading volume, Journal of Business and Economic Statistics 18, 410426.", "Lux, T. (1997), Time variation of second moments from a noise trader/infection model, Journal of Economic Dynamics and Control 22, 138.", "Lux, T. (2002), Financial power laws: Empirical evidence, models and mechanisms, Technical report, University of Kiel, Kiel, Germany.", "Mackie-Mason, J. K. & Wellman, M. P. (2005), Automated markets and trading agents, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "Mandelbrot, B. B.\n(1963), The variation of certain speculative prices, Journal of Business 36, 394419.", "Mantegna, R. N. & Stanley, H. E. (1999), An introduction to econophysics: Correlations and compexity in Finance, Cambridge University Press, Cambridge, UK.", "Marey, P. S. (2004), Exchange rate expectations: controlled experiments with articial traders, Journal of International Money and Finance 23, 283304.", "Marimon, R., McGrattan, E. & Sargent, T. J.\n(1990), Money as a medium of exchange in an economy with articially intelligent agents, Journal of Economic Dynamics and Control 14, 329373.", "Marks, R. (2005), Market design, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "McQueen, G. & Vorkink, K. (2004), Whence GARCH?\nA preference-based explanation for conditional volatility, Review of Financial Studies 17, 915949.", "Mehra, R. (January/February 2003), The equity premium: Why is it a puzzle?\n, Financial Analysts Journal pp.\n5469.", "Mehra, R. & Prescott, E. C. (1988), The equity risk premium: A solution?\n, Journal of Monetary Economics", "Merton, R. (1971), Optimum consumption and portfolio rules in a continuous-time model, Journal of Economic Theory 3, 373413.", "Mitra, K. (2005), Is more data better?\n, Journal of Economic Behavior and Organization 56, 263272.", "Neely, C., Weller, P. & Dittmar, R. (1997), Is technical analysis in the foreign exchange market protable?\na genetic programming approach, Journal of Financial and Quantitative Analysis 32, 40526.", "Noe, T., Rebello, M. & Wang, J.\n(2003), Corporate nancing: An articial agent-based analysis, Journal of Finance 63, 943973.", "Palmer, R., Arthur, W. B., Holland, J. H., LeBaron, B.\n& Tayler, P. (1994), Articial economic life: A simple model of a stock market, Physica D 75, 264274.", "Polhill, J. G., Izquierdo, L. R. & Gotts, N. M. (2005), The ghost in the Model (and other eects of oating point arithmetic), Journal of Articial Societies and Social Simulation 8.", "Raberto, M., Cincotti, S., Focardi, S. M. & Marchesi, M. (2001), Agent-based simulation of a nancial market, Physica A 299, 319327.", "Reitz, S. & Westerho, F. (2004), Commodity price cycles and heterogeneous speculators: A STAR-GARCH model, Technical report, University of Osnabruck, Dept.\nof Economics, Osnabruck, Germany.", "Rieck, C. (1994), Evolutionary simulation of asset trading strategies, in E. Hillebrand & J. Stender, eds, Many-Agent Simulation and Articial Life, IOS Press.", "Routledge, B. R. (1999), Adaptive learning in nancial markets, Review of Financial Studies 12, 11651202.", "Routledge, B. R. (2001), Genetic algorithm learning to choose and use information, Macroeconomic Dynamics 5, 303325.", "Shiller, R. J.\n(2003), From ecient market theory to behavioral nance, Journal of Economic Perspectives", "Solow, A., Costello, C. & Ward, M. (2003), Testing the power law model for discrete size data, The American Naturalist 162(5), 685689.", "Stauer, D. & Sornette, D. (1999), Self-organized percolation model for stock market uctuations, Physica A 271, 496506.", "Tay, N. S. P. & Linn, S. C. (2001), Fuzzy inductive reasoning, expectation formation and the behavior of security prices, Journal of Economic Dynamics and Control 25, 321362.", "Tesfatsion, L. (forthcoming 2005), Agent-based computational economics: A constructive approach to economic theory, in K. L. Judd & L. Tesfatsion, eds, Handbook of Computational Economics, Elsevier.", "Vigfusson, R. (1997), Switching between chartists and fundamentalists: A Markov regime-switching approach, International Journal of Finance and Economics 2, 291305.", "Vriend, N. (2000), An illustration of the essential dierence between individual and social learning, and its consequences for computational analysis, Journal of Economic Dynamics and Control 24, 119.", "Westerho, F. (2003a), Central bank intervention and feedback traders, International Financial Market, Institutions, and Money 13, 419427.", "Westerho, F. (2003c), Market-maker, inventory control and foreign exchange dynamics, Quantitative Finance 3, 363369.", "Westerho, F. (2003d), Speculative markets and the eectiveness of price limits, Journal of Economic Dynamics and Control 28, 493508.", "Westerho, F. H. & Reitz, S. (2003), Nonlinearities and cyclical behavior: The role of chartists and fundamentalists, Studies in Nonlinear Dynamics and Econometrics 7.", "Winker, P. & Gilli, M. (2001), Indirect estimation of the parameters of agent based models of nancial markets, Technical Report 38, FAME.", "Yang, J.\n(2002), Agent-based Modelling and Market Microstructure, PhD thesis, Concordia University, Montreal, Canada.", "Yeh, C. H. (2003), Tick size and market performance, Technical report, Yuan Ze University, Chungli, Taiwan.", "Youssefmir, M. & Huberman, B. A.\n(1997), Clustered volatility in multiagent dynamics, Journal of Economic Behavior and Organization 32, 101118.", "Zschischang, E. & Lux, T. (2001), Some new results on the Levy, Levy, and Solomon microscopic stock market model, Physica A 291, 563573.", "This is a short description of some of the multi-agent computational models considered here along with their design structures described in section 2.\nPreferences describe the types of preferences used by agents.\nPrice determination describes the method for determining asset prices.\nEvolution refers to which computational evolution mechanisms, if any, are used.\nFitness is the tness measure used to evolve strategies, and to determine agent strategy choices.\nStrategy representation is the way strategies are stored in the computer.\nOften this is a predened functional form, and the representation is simply a vector of real parameters.\nGA stands for the genetic algorithm.\nCARA and CRRA are constant absolute risk aversion, and constant relative risk aversion, respectively.", "AURORA, Ohio, Aug. 7, 2014 /PRNewswire/ -- TCP International Holdings Ltd. (NYSE: TCPI), a leading global manufacturer and distributor of energy efficient lighting technologies, today announced financial results for its second quarter ended June 30, 2014.", "Net sales for the second quarter were $112.5 million, an 11% increase compared with $101.1 million in the first quarter of 2014 and a 1% increase compared with $111.2 million in the second quarter of 2013.\nNet income in the second quarter was $2.0 million, or $0.10 per diluted share, compared with $3.9 million, or $0.19 per diluted share, in the first quarter of 2014 and compared with $4.6 million, or $0.22 per diluted share, in the second quarter of 2013.", "\"Our sales for the second quarter reflected our ongoing success to expand our LED product line in both our commercial and industrial and retail sales channels,\" said Ellis Yan, TCP's Chairman and CEO.\n\"Moving forward, we expect to leverage the investments we have made in our people and infrastructure to drive the continued growth of our LED product line.\"", " Net sales were $112.5 million, an increase of $11.4 million, or 11%, from the first quarter of 2014 and an increase of $1.3 million, or 1%, from the second quarter of 2013.", " LED sales were $46.0 million, an increase of $9.7 million, or 27%, from the first quarter of 2014 and an increase of $18.2 million, or 65%, from the second quarter of 2013, driven by increased sales in the commercial and industrial, or C&I, channel and with Walmart.", " CFL sales were $59.5 million, roughly flat from the first quarter of 2014 and down $12.4 million, or 17%, from the second quarter of 2013, primarily due to the transition to LEDs in the C&I channel and lower volume with The Home Depot.", " Gross margin was 22.7%, down from 24.5% in the first quarter of 2014 and down from 24.3% in the second quarter of 2013 due to the absence of favorable profit margins on a one-time order in 2013 and an increase in the provision for excess and obsolete inventory.", " Selling, general and administrative expenses were $20.4 million, an increase of $3.5 million from the first quarter of 2014 and an increase of $3.8 million from the second quarter of 2013 due to higher payroll largely attributable to the expansion of our sales force and marketing team to serve the C&I channel, increased marketing costs, and share-based compensation expenses for new awards granted in connection with the IPO.", " Net income was $2.0 million, a decrease from $3.9 million in the first quarter of 2014 and a decrease from $4.6 million in the second quarter of 2013.\nDiluted earnings per share were $0.10, a decrease from diluted earnings per share of $0.19 in the first quarter of 2014 and a decrease from diluted earnings per share of $0.22 in the second quarter of 2013.", " Adjusted EBITDA was $7.7 million, compared to $10.0 million in the first quarter of 2014 and $12.4 million in the second quarter of 2013.", "At June 30, 2014, cash and cash equivalents were $16.1 million, down from $23.0 million at March 31, 2014.\nOn July 1, 2014, TCP completed an initial public offering generating proceeds of $78.6 million, before deducting expenses of the offering estimated at $8.8 million.\nOn a pro forma basis, after giving effect of the offering that will be recorded in the third quarter of 2014, the Company's cash and cash equivalents were $85.9 million.\nCombined short-term loans and long-term debt was $144.2 million at June 30, 2014, down from $146.8 million at March 31, 2014. We intend to use the net proceeds from our offering to acquire manufacturing equipment to expand our LED manufacturing capacity, for the repayment of indebtedness outstanding and for general corporate purposes.", "Conference Call and Webcast Information The Company will host a conference call today, August 7, 2014, at 4:30 p.m. Eastern Time (1:30 p.m. Pacific Time).\nChief Executive Officer Ellis Yan and Chief Financial Officer Brian Catlett will present an overview of the second quarter 2014 financial results, discuss current business conditions, and respond to questions.\nThe call will be available, live, to interested parties by dialing (888) 539-3696.\nFor international callers, please dial (719) 325-2362.\nThe Conference ID number is 7227670.\nA live webcast will also be available in the Investors Relations section of the TCP website at: http://investors.tcpi.com.\nA replay of the webcast will be available through the Investor Relations section of the Company's web site approximately two hours after the conclusion of the call and remain available for approximately 30 calendar days.", "Non-GAAP Adjusted EBITDA We present the non-GAAP financial measure \"Adjusted EBITDA\" as a supplemental measure of our performance.\nThis non- GAAP financial measure is not a measure of financial performance or liquidity calculated in accordance with accounting principles generally accepted in the United States (U.S. GAAP), and should be viewed as a supplement to, not a substitute for, our results of operations presented on the basis of U.S. GAAP.\nWe define EBITDA as net income before interest expense, income taxes, depreciation and amortization, and Adjusted EBITDA as EBITDA before net foreign currency losses (gains), litigation settlements, share-based compensation expense and other non-recurring items.\nAdjusted EBITDA is not necessarily comparable to similarly titled measures reported by other companies.\nAdjusted EBITDA may exclude certain financial information that some may consider important in evaluating our financial performance.\nAdjusted EBITDA may not be indicative of historical operating results, and we do not intend for it to be predictive of future results of operations.\nWe believe the use of Adjusted EBITDA as a metric assists our board, management and investors in comparing our operating performance on a consistent basis because it removes the impact of our capital structure (i.e., interest expense), asset base (i.e., depreciation and amortization) and tax structure, as well as certain items that affect inter-period comparability.", "About TCP TCP is a leading global manufacturer and distributor of energy efficient lighting technologies.\nTCP's extensive product offerings include LED and CFL lamps and fixtures, internet-based lighting control solutions and other energy efficient lighting products.\nTCP has the largest combined number of LED and CFL ENERGY STAR compliant lighting products.\nTCP was named a 2014 ENERGY STAR Partner of the Year by the U.S. Environmental Protection Agency.\nTCP's products are currently offered through thousands of retail and C&I distributors.\nSince TCP's inception, it has sold more than one billion energy efficient lighting products.\nFor more information, visit http://www.tcpi.com.", "Forward Looking Statements Certain statements in this release may constitute \"forward-looking\" statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934 based on management's current opinions, expectations, beliefs, plans, objectives, assumptions or projections regarding future events or future results.\nForward-looking statements in this press release include, but are not limited to, the Company's expectation regarding the growth of its LED product line.\nThese forward-looking statements are only predictions, not historical fact, and involve certain risks and uncertainties, as well as assumptions.\nActual results, levels of activity, performance, achievements and events could differ materially from those stated, anticipated or implied by such forward-looking statements.\nWhile TCP believes that its assumptions are reasonable, it is very difficult to predict the impact of known factors, and, of course, it is impossible to anticipate all factors that could affect actual results.\nThere are a number of risks and uncertainties that could cause actual results to differ materially from forward-looking statements made herein.\nSuch forward-looking statements are made only as of the date of this release.\nTCP expressly disclaims any obligation or undertaking to release any updates or revisions to any forward-looking statements contained herein to reflect any change in its expectations with regard thereto or changes in events, conditions or circumstances on which any statement is based.", "Commitments and contingencies Shareholders' equity: Common stock, CHF 1.00 par value; 41,107 shares authorized; 20,553"]